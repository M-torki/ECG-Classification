{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sprint4: xResNet/Inception_icbeb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-torki/ECG-Classification/blob/main/sprint4_xResNet_Inception_icbeb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQhcIBu7oGKn"
      },
      "source": [
        "This notebook is based on the paper: \n",
        "\n",
        "**[Deep Learning for ECG Analysis: Benchmarks and Insights from PTB-XL](https://ieeexplore.ieee.org/document/9190034)**\n",
        "\n",
        "The related codes are available on this [Github](https://github.com/helme/ecg_ptbxl_benchmarking/) \n",
        "\n",
        "link to [PTB XL](https://physionet.org/content/ptb-xl/1.0.1/) database, \n",
        "link to [ICBEB2018](http://2018.icbeb.org/Challenge.html) database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wORp-jjQCMX-",
        "outputId": "f17463c7-a693-4488-a1e7-9d34ee8d6def"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_D850nzCiSq",
        "outputId": "98c3e8db-9566-4b0b-8dc7-38cf330b8944"
      },
      "source": [
        "cd /gdrive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1144sRmJVHVx",
        "outputId": "f702d40a-02e6-44a1-bcc5-2be0178534f0"
      },
      "source": [
        "!pip install wfdb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wfdb\n",
            "  Downloading wfdb-3.4.0-py3-none-any.whl (137 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▍                             | 10 kB 35.7 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 20 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 137 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna>=2.2 in /usr/local/lib/python3.7/dist-packages (from wfdb) (2.10)\n",
            "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.7/dist-packages (from wfdb) (2.23.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.3.1)\n",
            "Requirement already satisfied: chardet>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (3.0.4)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.10.1 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.19.5)\n",
            "Collecting threadpoolctl>=1.0.0\n",
            "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: urllib3>=1.22 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.4.2 in /usr/local/lib/python3.7/dist-packages (from wfdb) (2.8.1)\n",
            "Requirement already satisfied: certifi>=2016.8.2 in /usr/local/lib/python3.7/dist-packages (from wfdb) (2021.5.30)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from wfdb) (0.22.2.post1)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (0.10.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from wfdb) (2.4.7)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from wfdb) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10.0->wfdb) (1.15.0)\n",
            "Installing collected packages: threadpoolctl, wfdb\n",
            "Successfully installed threadpoolctl-2.2.0 wfdb-3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amteMY4fRNlj"
      },
      "source": [
        "# !git clone https://github.com/helme/ecg_ptbxl_benchmarking/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30J1OC6V8Dli",
        "cellView": "form"
      },
      "source": [
        "#@title Download ICBEB\n",
        "!mkdir -p ICBEB\n",
        "!cd ICBEB\n",
        "!wget http://2018.icbeb.org/file/REFERENCE.csv\n",
        "!wget http://hhbucket.oss-cn-hongkong.aliyuncs.com/TrainingSet1.zip\n",
        "!wget http://hhbucket.oss-cn-hongkong.aliyuncs.com/TrainingSet2.zip\n",
        "!wget http://hhbucket.oss-cn-hongkong.aliyuncs.com/TrainingSet3.zip\n",
        "!unzip TrainingSet1.zip\n",
        "!unzip TrainingSet2.zip\n",
        "!unzip TrainingSet3.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib6_2wBzN6wn",
        "cellView": "form"
      },
      "source": [
        "#@title stratisfy\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "from tqdm import tqdm\n",
        "\n",
        "def stratisfy_df(df, new_col_name, n_folds=10, nr_clean_folds=0):\n",
        "    # compute qualities as described in PTB-XL report\n",
        "    quals = []\n",
        "    for i, row in df.iterrows():\n",
        "        q = 0\n",
        "        if 'validated_by_human' in df.columns:\n",
        "            if row.validated_by_human == True:\n",
        "                q = 1\n",
        "        quals.append(q)\n",
        "    df['quality'] = quals\n",
        "\n",
        "    # create stratisfied folds according to patients\n",
        "    pat_ids = np.array(sorted(list(set(df.patient_id.values))))\n",
        "    plabels = []\n",
        "    pquals = []\n",
        "    ecgs_per_patient = []\n",
        "\n",
        "    for pid in tqdm(pat_ids):\n",
        "        sel = df[df.patient_id == pid]\n",
        "        l = np.concatenate([list(d.keys())for d in sel.scp_codes.values])\n",
        "        if sel.sex.values[0] == 0:\n",
        "            gender='male'\n",
        "        else:\n",
        "            gender='female'\n",
        "        l = np.concatenate((l, [gender]*len(sel)))\n",
        "        for age in sel.age.values:\n",
        "            if age < 20:\n",
        "                l = np.concatenate((l,['<20']))\n",
        "            elif age >= 20 and age < 40:\n",
        "                l = np.concatenate((l,['20-40']))\n",
        "            elif age >= 40 and age < 60:\n",
        "                l = np.concatenate((l,['40-60']))\n",
        "            elif age >= 60 and age < 80:\n",
        "                l = np.concatenate((l,['60-80']))\n",
        "            elif age >= 80:\n",
        "                l = np.concatenate((l,['>=80']))\n",
        "        plabels.append(l)\n",
        "        ecgs_per_patient.append(len(sel))\n",
        "        pquals.append(sel.quality.min())\n",
        "    classes = sorted(list(set([item for sublist in plabels for item in sublist])))\n",
        "\n",
        "    stratified_data_ids, stratified_data = stratify(plabels, classes, [1/n_folds]*n_folds, pquals, ecgs_per_patient, nr_clean_folds)\n",
        "\n",
        "    df[new_col_name] = np.zeros(len(df)).astype(int)\n",
        "    for fold_i, fold_ids in tqdm(enumerate(stratified_data_ids)):\n",
        "        ipat_ids = [pat_ids[pid] for pid in fold_ids]\n",
        "        df[new_col_name][df.patient_id.isin(ipat_ids)] = fold_i + 1\n",
        "\n",
        "    return df\n",
        "\n",
        "def stratify(data, classes, ratios, qualities, ecgs_per_patient, nr_clean_folds=1):\n",
        "    \"\"\"Stratifying procedure. Modified from https://vict0rs.ch/2018/05/24/sample-multilabel-dataset/ (based on Sechidis 2011)\n",
        "    data is a list of lists: a list of labels, for each sample.\n",
        "        Each sample's labels should be ints, if they are one-hot encoded, use one_hot=True\n",
        "    \n",
        "    classes is the list of classes each label can take\n",
        "    ratios is a list, summing to 1, of how the dataset should be split\n",
        "    qualities: quality per entry (only >0 can be assigned to clean folds; 4 will always be assigned to final fold)\n",
        "    ecgs_per_patient: list with number of ecgs per sample\n",
        "    nr_clean_folds: the last nr_clean_folds can only take clean entries\n",
        "    \"\"\"\n",
        "    np.random.seed(0) # fix the random seed\n",
        "\n",
        "    # data is now always a list of lists; len(data) is the number of patients; data[i] is the list of all labels for patient i (possibly multiple identical entries)\n",
        "\n",
        "    #size is the number of ecgs\n",
        "    size = np.sum(ecgs_per_patient)\n",
        "\n",
        "    # Organize data per label: for each label l, per_label_data[l] contains the list of patients\n",
        "    # in data which have this label (potentially multiple identical entries)\n",
        "    per_label_data = {c: [] for c in classes}\n",
        "    for i, d in enumerate(data):\n",
        "        for l in d:\n",
        "            per_label_data[l].append(i)\n",
        "\n",
        "    # In order not to compute lengths each time, they are tracked here.\n",
        "    subset_sizes = [r * size for r in ratios] #list of subset_sizes in terms of ecgs\n",
        "    per_label_subset_sizes = { c: [r * len(per_label_data[c]) for r in ratios] for c in classes } #dictionary with label: list of subset sizes in terms of patients\n",
        "\n",
        "    # For each subset we want, the set of sample-ids which should end up in it\n",
        "    stratified_data_ids = [set() for _ in range(len(ratios))] #initialize empty\n",
        "\n",
        "    # For each sample in the data set\n",
        "    print(\"Assigning patients to folds...\")\n",
        "    size_prev=size+1 #just for output\n",
        "    while size > 0:\n",
        "        if(int(size_prev/1000) > int(size/1000)):\n",
        "            print(\"Remaining patients/ecgs to distribute:\",size,\"non-empty labels:\", np.sum([1 for l, label_data in per_label_data.items() if len(label_data)>0]))\n",
        "        size_prev=size\n",
        "        # Compute |Di| \n",
        "        lengths = {\n",
        "            l: len(label_data)\n",
        "            for l, label_data in per_label_data.items()\n",
        "        } #dictionary label: number of ecgs with this label that have not been assigned to a fold yet\n",
        "        try:\n",
        "            # Find label of smallest |Di|\n",
        "            label = min({k: v for k, v in lengths.items() if v > 0}, key=lengths.get)\n",
        "        except ValueError:\n",
        "            # If the dictionary in `min` is empty we get a Value Error. \n",
        "            # This can happen if there are unlabeled samples.\n",
        "            # In this case, `size` would be > 0 but only samples without label would remain.\n",
        "            # \"No label\" could be a class in itself: it's up to you to format your data accordingly.\n",
        "            break\n",
        "        # For each patient with label `label` get patient and corresponding counts\n",
        "        unique_samples, unique_counts = np.unique(per_label_data[label],return_counts=True)\n",
        "        idxs_sorted = np.argsort(unique_counts, kind='stable')[::-1]\n",
        "        unique_samples = unique_samples[idxs_sorted] # this is a list of all patient ids with this label sort by size descending\n",
        "        unique_counts =  unique_counts[idxs_sorted] # these are the corresponding counts\n",
        "        \n",
        "        # loop through all patient ids with this label\n",
        "        for current_id, current_count in zip(unique_samples,unique_counts):\n",
        "            \n",
        "            subset_sizes_for_label = per_label_subset_sizes[label] #current subset sizes for the chosen label\n",
        "\n",
        "            #if quality is bad remove clean folds (i.e. sample cannot be assigned to clean folds)\n",
        "            if(qualities[current_id] < 1):\n",
        "                subset_sizes_for_label = subset_sizes_for_label[:len(ratios)-nr_clean_folds]\n",
        "\n",
        "            # Find argmax clj i.e. subset in greatest need of the current label\n",
        "            largest_subsets = np.argwhere(subset_sizes_for_label == np.amax(subset_sizes_for_label)).flatten()\n",
        "            \n",
        "            # if there is a single best choice: assign it\n",
        "            if len(largest_subsets) == 1:\n",
        "                subset = largest_subsets[0]\n",
        "            # If there is more than one such subset, find the one in greatest need of any label\n",
        "            else:\n",
        "                largest_subsets2 = np.argwhere(np.array(subset_sizes)[largest_subsets] == np.amax(np.array(subset_sizes)[largest_subsets])).flatten()\n",
        "                subset = largest_subsets[np.random.choice(largest_subsets2)]\n",
        "\n",
        "            # Store the sample's id in the selected subset\n",
        "            stratified_data_ids[subset].add(current_id)\n",
        "\n",
        "            # There is current_count fewer samples to distribute\n",
        "            size -= ecgs_per_patient[current_id]\n",
        "            # The selected subset needs current_count fewer samples\n",
        "            subset_sizes[subset] -= ecgs_per_patient[current_id]\n",
        "\n",
        "            # In the selected subset, there is one more example for each label\n",
        "            # the current sample has\n",
        "            for l in data[current_id]:\n",
        "                per_label_subset_sizes[l][subset] -= 1\n",
        "               \n",
        "            # Remove the sample from the dataset, meaning from all per_label dataset created\n",
        "            for x in per_label_data.keys():\n",
        "                per_label_data[x] = [y for y in per_label_data[x] if y!=current_id]\n",
        "              \n",
        "    # Create the stratified dataset as a list of subsets, each containing the orginal labels\n",
        "    stratified_data_ids = [sorted(strat) for strat in stratified_data_ids]\n",
        "    stratified_data = [\n",
        "        [data[i] for i in strat] for strat in stratified_data_ids\n",
        "    ]\n",
        "\n",
        "    # Return both the stratified indexes, to be used to sample the `features` associated with your labels\n",
        "    # And the stratified labels dataset\n",
        "\n",
        "    return stratified_data_ids, stratified_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "jNxoOznuKw_S"
      },
      "source": [
        "#@title convert_ICBEB\n",
        "import os\n",
        "import pandas as pd\n",
        "import wfdb\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from scipy.ndimage import zoom\n",
        "from scipy.io import loadmat\n",
        "# from stratisfy import stratisfy_df\n",
        "\n",
        "output_folder = './icbeb/'\n",
        "output_datafolder_100 = output_folder+ '/records100/'\n",
        "output_datafolder_500 = output_folder+ '/records500/'\n",
        "if not os.path.exists(output_folder):\n",
        "    os.mkdir(output_folder)\n",
        "if not os.path.exists(output_datafolder_100):\n",
        "    os.makedirs(output_datafolder_100)\n",
        "if not os.path.exists(output_datafolder_500):\n",
        "    os.makedirs(output_datafolder_500)\n",
        "    \n",
        "def store_as_wfdb(signame, data, sigfolder, fs):\n",
        "    channel_itos=['I', 'II', 'III', 'AVR', 'AVL', 'AVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
        "    wfdb.wrsamp(signame,\n",
        "                fs=fs,\n",
        "                sig_name=channel_itos, \n",
        "                p_signal=data,\n",
        "                units=['mV']*len(channel_itos),\n",
        "                fmt = ['16']*len(channel_itos), \n",
        "                write_dir=sigfolder)  \n",
        "\n",
        "df_reference = pd.read_csv('./ICBEB/REFERENCE.csv')\n",
        "\n",
        "label_dict = {1:'NORM', 2:'AFIB', 3:'1AVB', 4:'CLBBB', 5:'CRBBB', 6:'PAC', 7:'VPC', 8:'STD_', 9:'STE_'}\n",
        "\n",
        "data = {'ecg_id':[], 'filename':[], 'validation':[], 'age':[], 'sex':[], 'scp_codes':[]}\n",
        "\n",
        "ecg_counter = 0\n",
        "for folder in ['TrainingSet1', 'TrainingSet2', 'TrainingSet3']:\n",
        "    filenames = os.listdir('./ICBEB/'+folder)\n",
        "    for filename in tqdm(filenames):\n",
        "        if filename.split('.')[1] == 'mat':\n",
        "            ecg_counter += 1\n",
        "            name = filename.split('.')[0]\n",
        "            sex, age, sig = loadmat('./ICBEB/'+folder+'/'+filename)['ECG'][0][0]\n",
        "            data['ecg_id'].append(ecg_counter)\n",
        "            data['filename'].append(name)\n",
        "            data['validation'].append(False)\n",
        "            data['age'].append(age[0][0])\n",
        "            data['sex'].append(1 if sex[0] == 'Male' else 0)\n",
        "            labels = df_reference[df_reference.Recording == name][['First_label' ,'Second_label' ,'Third_label']].values.flatten()\n",
        "            labels = labels[~np.isnan(labels)].astype(int)\n",
        "            data['scp_codes'].append({label_dict[key]:100 for key in labels})\n",
        "            store_as_wfdb(str(ecg_counter), sig.T, output_datafolder_500, 500)\n",
        "            down_sig = np.array([zoom(channel, .2) for channel in sig])\n",
        "            store_as_wfdb(str(ecg_counter), down_sig.T, output_datafolder_100, 100)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbSn-36AJuUR"
      },
      "source": [
        "# cp ./ptb_xl/ptbxl/scp_statements.csv ./icbeb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv7PduHCtcID",
        "outputId": "b34322f5-3bf2-4d6b-fa20-232ef67d2288"
      },
      "source": [
        "# ls ./icbeb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "icbeb_database.csv  \u001b[0m\u001b[01;34mrecords100\u001b[0m/  \u001b[01;34mrecords500\u001b[0m/  scp_statements.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ig75yuxRWEE",
        "outputId": "d46b255a-9e85-4e8a-f0dd-ec213fd21f40"
      },
      "source": [
        "cd ./ecg_ptbxl_benchmarking/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/.shortcut-targets-by-id/1j3ncHY23bba4nXCRAt52Fr8YgGZpml9-/ecg_ptbxl_benchmarking\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ytFYZfLRnMp",
        "outputId": "e7e11259-8924-42b1-e017-d3e1ca825215"
      },
      "source": [
        "cd code/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/.shortcut-targets-by-id/1j3ncHY23bba4nXCRAt52Fr8YgGZpml9-/ecg_ptbxl_benchmarking/code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3qSI1C11wkq",
        "cellView": "form"
      },
      "source": [
        "#@title utils\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import glob\n",
        "import pickle\n",
        "import copy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import wfdb\n",
        "import ast\n",
        "from sklearn.metrics import classification_report, fbeta_score, roc_auc_score, roc_curve, roc_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
        "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
        "import warnings\n",
        "\n",
        "# EVALUATION STUFF\n",
        "def generate_results(idxs, y_true, y_pred, thresholds):\n",
        "    return evaluate_experiment(y_true[idxs], y_pred[idxs], thresholds)\n",
        "\n",
        "def evaluate_experiment(y_true, y_pred, thresholds=None):\n",
        "    results = {}\n",
        "\n",
        "    if not thresholds is None:\n",
        "        # binary predictions\n",
        "        y_pred_binary = apply_thresholds(y_pred, thresholds)\n",
        "        # PhysioNet/CinC Challenges metrics\n",
        "        challenge_scores = challenge_metrics(y_true, y_pred_binary, beta1=2, beta2=2)\n",
        "        results['F_beta_macro'] = challenge_scores['F_beta_macro']\n",
        "        results['G_beta_macro'] = challenge_scores['G_beta_macro']\n",
        "\n",
        "    # label based metric\n",
        "    results['macro_auc'] = roc_auc_score(y_true, y_pred, average='macro')\n",
        "    \n",
        "    df_result = pd.DataFrame(results, index=[0])\n",
        "    return df_result\n",
        "\n",
        "def challenge_metrics(y_true, y_pred, beta1=2, beta2=2, class_weights=None, single=False):\n",
        "    f_beta = 0\n",
        "    g_beta = 0\n",
        "    if single: # if evaluating single class in case of threshold-optimization\n",
        "        sample_weights = np.ones(y_true.sum(axis=1).shape)\n",
        "    else:\n",
        "        sample_weights = y_true.sum(axis=1)\n",
        "    for classi in range(y_true.shape[1]):\n",
        "        y_truei, y_predi = y_true[:,classi], y_pred[:,classi]\n",
        "        TP, FP, TN, FN = 0.,0.,0.,0.\n",
        "        for i in range(len(y_predi)):\n",
        "            sample_weight = sample_weights[i]\n",
        "            if y_truei[i]==y_predi[i]==1: \n",
        "                TP += 1./sample_weight\n",
        "            if ((y_predi[i]==1) and (y_truei[i]!=y_predi[i])): \n",
        "                FP += 1./sample_weight\n",
        "            if y_truei[i]==y_predi[i]==0: \n",
        "                TN += 1./sample_weight\n",
        "            if ((y_predi[i]==0) and (y_truei[i]!=y_predi[i])): \n",
        "                FN += 1./sample_weight \n",
        "        f_beta_i = ((1+beta1**2)*TP)/((1+beta1**2)*TP + FP + (beta1**2)*FN)\n",
        "        g_beta_i = (TP)/(TP+FP+beta2*FN)\n",
        "\n",
        "        f_beta += f_beta_i\n",
        "        g_beta += g_beta_i\n",
        "\n",
        "    return {'F_beta_macro':f_beta/y_true.shape[1], 'G_beta_macro':g_beta/y_true.shape[1]}\n",
        "\n",
        "def get_appropriate_bootstrap_samples(y_true, n_bootstraping_samples):\n",
        "    samples=[]\n",
        "    while True:\n",
        "        ridxs = np.random.randint(0, len(y_true), len(y_true))\n",
        "        if y_true[ridxs].sum(axis=0).min() != 0:\n",
        "            samples.append(ridxs)\n",
        "            if len(samples) == n_bootstraping_samples:\n",
        "                break\n",
        "    return samples\n",
        "\n",
        "def find_optimal_cutoff_threshold(target, predicted):\n",
        "    \"\"\" \n",
        "    Find the optimal probability cutoff point for a classification model related to event rate\n",
        "    \"\"\"\n",
        "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
        "    optimal_idx = np.argmax(tpr - fpr)\n",
        "    optimal_threshold = threshold[optimal_idx]\n",
        "    return optimal_threshold\n",
        "\n",
        "def find_optimal_cutoff_thresholds(y_true, y_pred):\n",
        "\treturn [find_optimal_cutoff_threshold(y_true[:,i], y_pred[:,i]) for i in range(y_true.shape[1])]\n",
        "\n",
        "def find_optimal_cutoff_threshold_for_Gbeta(target, predicted, n_thresholds=100):\n",
        "    thresholds = np.linspace(0.00,1,n_thresholds)\n",
        "    scores = [challenge_metrics(target, predicted>t, single=True)['G_beta_macro'] for t in thresholds]\n",
        "    optimal_idx = np.argmax(scores)\n",
        "    return thresholds[optimal_idx]\n",
        "\n",
        "def find_optimal_cutoff_thresholds_for_Gbeta(y_true, y_pred):\n",
        "    print(\"optimize thresholds with respect to G_beta\")\n",
        "    return [find_optimal_cutoff_threshold_for_Gbeta(y_true[:,k][:,np.newaxis], y_pred[:,k][:,np.newaxis]) for k in tqdm(range(y_true.shape[1]))]\n",
        "\n",
        "def apply_thresholds(preds, thresholds):\n",
        "\t\"\"\"\n",
        "\t\tapply class-wise thresholds to prediction score in order to get binary format.\n",
        "\t\tBUT: if no score is above threshold, pick maximum. This is needed due to metric issues.\n",
        "\t\"\"\"\n",
        "\ttmp = []\n",
        "\tfor p in preds:\n",
        "\t\ttmp_p = (p > thresholds).astype(int)\n",
        "\t\tif np.sum(tmp_p) == 0:\n",
        "\t\t\ttmp_p[np.argmax(p)] = 1\n",
        "\t\ttmp.append(tmp_p)\n",
        "\ttmp = np.array(tmp)\n",
        "\treturn tmp\n",
        "\n",
        "# DATA PROCESSING STUFF\n",
        "\n",
        "def load_dataset(path, sampling_rate, release=False):\n",
        "    if path.split('/')[-2] == 'ptbxl':\n",
        "        # load and convert annotation data\n",
        "        Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')\n",
        "        Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
        "\n",
        "        # Load raw signal data\n",
        "        X = load_raw_data_ptbxl(Y, sampling_rate, path)\n",
        "\n",
        "    elif path.split('/')[-2] == 'ICBEB':\n",
        "        # load and convert annotation data\n",
        "        Y = pd.read_csv(path+'icbeb_database.csv', index_col='ecg_id')\n",
        "        Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
        "\n",
        "        # Load raw signal data\n",
        "        X = load_raw_data_icbeb(Y, sampling_rate, path)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "def load_raw_data_icbeb(df, sampling_rate, path):\n",
        "\n",
        "    if sampling_rate == 100:\n",
        "        if os.path.exists(path + 'raw100.npy'):\n",
        "            data = np.load(path+'raw100.npy', allow_pickle=True)\n",
        "        else:\n",
        "            data = [wfdb.rdsamp(path + 'records100/'+str(f)) for f in tqdm(df.index)]\n",
        "            data = np.array([signal for signal, meta in data])\n",
        "            pickle.dump(data, open(path+'raw100.npy', 'wb'), protocol=4)\n",
        "    elif sampling_rate == 500:\n",
        "        if os.path.exists(path + 'raw500.npy'):\n",
        "            data = np.load(path+'raw500.npy', allow_pickle=True)\n",
        "        else:\n",
        "            data = [wfdb.rdsamp(path + 'records500/'+str(f)) for f in tqdm(df.index)]\n",
        "            data = np.array([signal for signal, meta in data])\n",
        "            pickle.dump(data, open(path+'raw500.npy', 'wb'), protocol=4)\n",
        "    return data\n",
        "\n",
        "def load_raw_data_ptbxl(df, sampling_rate, path):\n",
        "    if sampling_rate == 100:\n",
        "        if os.path.exists(path + 'raw100.npy'):\n",
        "            data = np.load(path+'raw100.npy', allow_pickle=True)\n",
        "        else:\n",
        "            data = [wfdb.rdsamp(path+f) for f in tqdm(df.filename_lr)]\n",
        "            data = np.array([signal for signal, meta in data])\n",
        "            pickle.dump(data, open(path+'raw100.npy', 'wb'), protocol=4)\n",
        "    elif sampling_rate == 500:\n",
        "        if os.path.exists(path + 'raw500.npy'):\n",
        "            data = np.load(path+'raw500.npy', allow_pickle=True)\n",
        "        else:\n",
        "            data = [wfdb.rdsamp(path+f) for f in tqdm(df.filename_hr)]\n",
        "            data = np.array([signal for signal, meta in data])\n",
        "            pickle.dump(data, open(path+'raw500.npy', 'wb'), protocol=4)\n",
        "    return data\n",
        "\n",
        "def compute_label_aggregations(df, folder, ctype):\n",
        "\n",
        "    df['scp_codes_len'] = df.scp_codes.apply(lambda x: len(x))\n",
        "\n",
        "    aggregation_df = pd.read_csv(folder+'scp_statements.csv', index_col=0)\n",
        "\n",
        "    if ctype in ['diagnostic', 'subdiagnostic', 'superdiagnostic']:\n",
        "\n",
        "        def aggregate_all_diagnostic(y_dic):\n",
        "            tmp = []\n",
        "            for key in y_dic.keys():\n",
        "                if key in diag_agg_df.index:\n",
        "                    tmp.append(key)\n",
        "            return list(set(tmp))\n",
        "\n",
        "        def aggregate_subdiagnostic(y_dic):\n",
        "            tmp = []\n",
        "            for key in y_dic.keys():\n",
        "                if key in diag_agg_df.index:\n",
        "                    c = diag_agg_df.loc[key].diagnostic_subclass\n",
        "                    if str(c) != 'nan':\n",
        "                        tmp.append(c)\n",
        "            return list(set(tmp))\n",
        "\n",
        "        def aggregate_diagnostic(y_dic):\n",
        "            tmp = []\n",
        "            for key in y_dic.keys():\n",
        "                if key in diag_agg_df.index:\n",
        "                    c = diag_agg_df.loc[key].diagnostic_class\n",
        "                    if str(c) != 'nan':\n",
        "                        tmp.append(c)\n",
        "            return list(set(tmp))\n",
        "\n",
        "        diag_agg_df = aggregation_df[aggregation_df.diagnostic == 1.0]\n",
        "        if ctype == 'diagnostic':\n",
        "            df['diagnostic'] = df.scp_codes.apply(aggregate_all_diagnostic)\n",
        "            df['diagnostic_len'] = df.diagnostic.apply(lambda x: len(x))\n",
        "        elif ctype == 'subdiagnostic':\n",
        "            df['subdiagnostic'] = df.scp_codes.apply(aggregate_subdiagnostic)\n",
        "            df['subdiagnostic_len'] = df.subdiagnostic.apply(lambda x: len(x))\n",
        "        elif ctype == 'superdiagnostic':\n",
        "            df['superdiagnostic'] = df.scp_codes.apply(aggregate_diagnostic)\n",
        "            df['superdiagnostic_len'] = df.superdiagnostic.apply(lambda x: len(x))\n",
        "    elif ctype == 'form':\n",
        "        form_agg_df = aggregation_df[aggregation_df.form == 1.0]\n",
        "\n",
        "        def aggregate_form(y_dic):\n",
        "            tmp = []\n",
        "            for key in y_dic.keys():\n",
        "                if key in form_agg_df.index:\n",
        "                    c = key\n",
        "                    if str(c) != 'nan':\n",
        "                        tmp.append(c)\n",
        "            return list(set(tmp))\n",
        "\n",
        "        df['form'] = df.scp_codes.apply(aggregate_form)\n",
        "        df['form_len'] = df.form.apply(lambda x: len(x))\n",
        "    elif ctype == 'rhythm':\n",
        "        rhythm_agg_df = aggregation_df[aggregation_df.rhythm == 1.0]\n",
        "\n",
        "        def aggregate_rhythm(y_dic):\n",
        "            tmp = []\n",
        "            for key in y_dic.keys():\n",
        "                if key in rhythm_agg_df.index:\n",
        "                    c = key\n",
        "                    if str(c) != 'nan':\n",
        "                        tmp.append(c)\n",
        "            return list(set(tmp))\n",
        "\n",
        "        df['rhythm'] = df.scp_codes.apply(aggregate_rhythm)\n",
        "        df['rhythm_len'] = df.rhythm.apply(lambda x: len(x))\n",
        "    elif ctype == 'all':\n",
        "        df['all_scp'] = df.scp_codes.apply(lambda x: list(set(x.keys())))\n",
        "\n",
        "    return df\n",
        "\n",
        "def select_data(XX,YY, ctype, min_samples, outputfolder):\n",
        "    # convert multilabel to multi-hot\n",
        "    mlb = MultiLabelBinarizer()\n",
        "\n",
        "    if ctype == 'diagnostic':\n",
        "        X = XX[YY.diagnostic_len > 0]\n",
        "        Y = YY[YY.diagnostic_len > 0]\n",
        "        mlb.fit(Y.diagnostic.values)\n",
        "        y = mlb.transform(Y.diagnostic.values)\n",
        "    elif ctype == 'subdiagnostic':\n",
        "        counts = pd.Series(np.concatenate(YY.subdiagnostic.values)).value_counts()\n",
        "        counts = counts[counts > min_samples]\n",
        "        YY.subdiagnostic = YY.subdiagnostic.apply(lambda x: list(set(x).intersection(set(counts.index.values))))\n",
        "        YY['subdiagnostic_len'] = YY.subdiagnostic.apply(lambda x: len(x))\n",
        "        X = XX[YY.subdiagnostic_len > 0]\n",
        "        Y = YY[YY.subdiagnostic_len > 0]\n",
        "        mlb.fit(Y.subdiagnostic.values)\n",
        "        y = mlb.transform(Y.subdiagnostic.values)\n",
        "    elif ctype == 'superdiagnostic':\n",
        "        counts = pd.Series(np.concatenate(YY.superdiagnostic.values)).value_counts()\n",
        "        counts = counts[counts > min_samples]\n",
        "        YY.superdiagnostic = YY.superdiagnostic.apply(lambda x: list(set(x).intersection(set(counts.index.values))))\n",
        "        YY['superdiagnostic_len'] = YY.superdiagnostic.apply(lambda x: len(x))\n",
        "        X = XX[YY.superdiagnostic_len > 0]\n",
        "        Y = YY[YY.superdiagnostic_len > 0]\n",
        "        mlb.fit(Y.superdiagnostic.values)\n",
        "        y = mlb.transform(Y.superdiagnostic.values)\n",
        "    elif ctype == 'form':\n",
        "        # filter\n",
        "        counts = pd.Series(np.concatenate(YY.form.values)).value_counts()\n",
        "        counts = counts[counts > min_samples]\n",
        "        YY.form = YY.form.apply(lambda x: list(set(x).intersection(set(counts.index.values))))\n",
        "        YY['form_len'] = YY.form.apply(lambda x: len(x))\n",
        "        # select\n",
        "        X = XX[YY.form_len > 0]\n",
        "        Y = YY[YY.form_len > 0]\n",
        "        mlb.fit(Y.form.values)\n",
        "        y = mlb.transform(Y.form.values)\n",
        "    elif ctype == 'rhythm':\n",
        "        # filter \n",
        "        counts = pd.Series(np.concatenate(YY.rhythm.values)).value_counts()\n",
        "        counts = counts[counts > min_samples]\n",
        "        YY.rhythm = YY.rhythm.apply(lambda x: list(set(x).intersection(set(counts.index.values))))\n",
        "        YY['rhythm_len'] = YY.rhythm.apply(lambda x: len(x))\n",
        "        # select\n",
        "        X = XX[YY.rhythm_len > 0]\n",
        "        Y = YY[YY.rhythm_len > 0]\n",
        "        mlb.fit(Y.rhythm.values)\n",
        "        y = mlb.transform(Y.rhythm.values)\n",
        "    elif ctype == 'all':\n",
        "        # filter \n",
        "        counts = pd.Series(np.concatenate(YY.all_scp.values)).value_counts()\n",
        "        counts = counts[counts > min_samples]\n",
        "        YY.all_scp = YY.all_scp.apply(lambda x: list(set(x).intersection(set(counts.index.values))))\n",
        "        YY['all_scp_len'] = YY.all_scp.apply(lambda x: len(x))\n",
        "        # select\n",
        "        X = XX[YY.all_scp_len > 0]\n",
        "        Y = YY[YY.all_scp_len > 0]\n",
        "        mlb.fit(Y.all_scp.values)\n",
        "        y = mlb.transform(Y.all_scp.values)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    # save LabelBinarizer\n",
        "    with open(outputfolder+'mlb.pkl', 'wb') as tokenizer:\n",
        "        pickle.dump(mlb, tokenizer)\n",
        "\n",
        "    return X, Y, y, mlb\n",
        "\n",
        "def preprocess_signals(X_train, X_validation, X_test, outputfolder):\n",
        "    # Standardize data such that mean 0 and variance 1\n",
        "    ss = StandardScaler()\n",
        "    ss.fit(np.vstack(X_train).flatten()[:,np.newaxis].astype(float))\n",
        "    \n",
        "    # Save Standardizer data\n",
        "    with open(outputfolder+'standard_scaler.pkl', 'wb') as ss_file:\n",
        "        pickle.dump(ss, ss_file)\n",
        "\n",
        "    return apply_standardizer(X_train, ss), apply_standardizer(X_validation, ss), apply_standardizer(X_test, ss)\n",
        "\n",
        "def apply_standardizer(X, ss):\n",
        "    X_tmp = []\n",
        "    for x in X:\n",
        "        x_shape = x.shape\n",
        "        X_tmp.append(ss.transform(x.flatten()[:,np.newaxis]).reshape(x_shape))\n",
        "    X_tmp = np.array(X_tmp)\n",
        "    return X_tmp\n",
        "\n",
        "\n",
        "# DOCUMENTATION STUFF\n",
        "\n",
        "def generate_ptbxl_summary_table(selection=None, folder='../output/'):\n",
        "\n",
        "    exps = ['exp0', 'exp1', 'exp1.1', 'exp1.1.1', 'exp2', 'exp3']\n",
        "    metric1 = 'macro_auc' \n",
        "\n",
        "    # get models\n",
        "    models = {}\n",
        "    for i, exp in enumerate(exps):\n",
        "        if selection is None:\n",
        "            exp_models = [m.split('/')[-1] for m in glob.glob(folder+str(exp)+'/models/*')]\n",
        "        else:\n",
        "            exp_models = selection\n",
        "        if i == 0:\n",
        "            models = set(exp_models)\n",
        "        else:\n",
        "            models = models.union(set(exp_models))\n",
        "\n",
        "    results_dic = {'Method':[], \n",
        "                'exp0_AUC':[], \n",
        "                'exp1_AUC':[], \n",
        "                'exp1.1_AUC':[], \n",
        "                'exp1.1.1_AUC':[], \n",
        "                'exp2_AUC':[],\n",
        "                'exp3_AUC':[]\n",
        "                }\n",
        "\n",
        "    for m in models:\n",
        "        results_dic['Method'].append(m)\n",
        "        \n",
        "        for e in exps:\n",
        "            \n",
        "            try:\n",
        "                me_res = pd.read_csv(folder+str(e)+'/models/'+str(m)+'/results/te_results.csv', index_col=0)\n",
        "    \n",
        "                mean1 = me_res.loc['point'][metric1]\n",
        "                unc1 = max(me_res.loc['upper'][metric1]-me_res.loc['point'][metric1], me_res.loc['point'][metric1]-me_res.loc['lower'][metric1])\n",
        "\n",
        "                results_dic[e+'_AUC'].append(\"%.3f(%.2d)\" %(np.round(mean1,3), int(unc1*1000)))\n",
        "\n",
        "            except FileNotFoundError:\n",
        "                results_dic[e+'_AUC'].append(\"--\")\n",
        "            \n",
        "            \n",
        "    df = pd.DataFrame(results_dic)\n",
        "    df_index = df[df.Method.isin(['naive', 'ensemble'])]\n",
        "    df_rest = df[~df.Method.isin(['naive', 'ensemble'])]\n",
        "    df = pd.concat([df_rest, df_index])\n",
        "    df.to_csv(folder+'results_ptbxl.csv')\n",
        "\n",
        "    titles = [\n",
        "        '### 1. PTB-XL: all statements',\n",
        "        '### 2. PTB-XL: diagnostic statements',\n",
        "        '### 3. PTB-XL: Diagnostic subclasses',\n",
        "        '### 4. PTB-XL: Diagnostic superclasses',\n",
        "        '### 5. PTB-XL: Form statements',\n",
        "        '### 6. PTB-XL: Rhythm statements'        \n",
        "    ]\n",
        "\n",
        "    # helper output function for markdown tables\n",
        "    our_work = 'https://arxiv.org/abs/2004.13701'\n",
        "    our_repo = 'https://github.com/helme/ecg_ptbxl_benchmarking/'\n",
        "    md_source = ''\n",
        "    for i, e in enumerate(exps):\n",
        "        md_source += '\\n '+titles[i]+' \\n \\n'\n",
        "        md_source += '| Model | AUC &darr; | paper/source | code | \\n'\n",
        "        md_source += '|---:|:---|:---|:---| \\n'\n",
        "        for row in df_rest[['Method', e+'_AUC']].sort_values(e+'_AUC', ascending=False).values:\n",
        "            md_source += '| ' + row[0].replace('fastai_', '') + ' | ' + row[1] + ' | [our work]('+our_work+') | [this repo]('+our_repo+')| \\n'\n",
        "    print(md_source)\n",
        "\n",
        "def ICBEBE_table(selection=None, folder='../output/'):\n",
        "    cols = ['macro_auc', 'F_beta_macro', 'G_beta_macro']\n",
        "\n",
        "    if selection is None:\n",
        "        models = [m.split('/')[-1].split('_pretrained')[0] for m in glob.glob(folder+'exp_ICBEB/models/*')]\n",
        "    else:\n",
        "        models = [] \n",
        "        for s in selection:\n",
        "            #if s != 'Wavelet+NN':\n",
        "                models.append(s)\n",
        "\n",
        "    data = []\n",
        "    for model in models:\n",
        "        me_res = pd.read_csv(folder+'exp_ICBEB/models/'+model+'/results/te_results.csv', index_col=0)\n",
        "        mcol=[]\n",
        "        for col in cols:\n",
        "            mean = me_res.ix['point'][col]\n",
        "            unc = max(me_res.ix['upper'][col]-me_res.ix['point'][col], me_res.ix['point'][col]-me_res.ix['lower'][col])\n",
        "            mcol.append(\"%.3f(%.2d)\" %(np.round(mean,3), int(unc*1000)))\n",
        "        data.append(mcol)\n",
        "    data = np.array(data)\n",
        "\n",
        "    df = pd.DataFrame(data, columns=cols, index=models)\n",
        "    df.to_csv(folder+'results_icbeb.csv')\n",
        "\n",
        "    df_rest = df[~df.index.isin(['naive', 'ensemble'])]\n",
        "    df_rest = df_rest.sort_values('macro_auc', ascending=False)\n",
        "    our_work = 'https://arxiv.org/abs/2004.13701'\n",
        "    our_repo = 'https://github.com/helme/ecg_ptbxl_benchmarking/'\n",
        "\n",
        "    md_source = '| Model | AUC &darr; |  F_beta=2 | G_beta=2 | paper/source | code | \\n'\n",
        "    md_source += '|---:|:---|:---|:---|:---|:---| \\n'\n",
        "    for i, row in enumerate(df_rest[cols].values):\n",
        "        md_source += '| ' + df_rest.index[i].replace('fastai_', '') + ' | ' + row[0] + ' | ' + row[1] + ' | ' + row[2] + ' | [our work]('+our_work+') | [this repo]('+our_repo+')| \\n'\n",
        "    print(md_source)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVqEuVHB0vm7",
        "cellView": "form"
      },
      "source": [
        "#@title Models definition\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from models.basic_conv1d import create_head1d, Flatten\n",
        "\n",
        "from enum import Enum\n",
        "import re\n",
        "#delegates\n",
        "import inspect\n",
        "\n",
        "def delegates(to=None, keep=False):\n",
        "    \"Decorator: replace `**kwargs` in signature with params from `to`\"\n",
        "    def _f(f):\n",
        "        if to is None: to_f,from_f = f.__base__.__init__,f.__init__\n",
        "        else:          to_f,from_f = to,f\n",
        "        sig = inspect.signature(from_f)\n",
        "        sigd = dict(sig.parameters)\n",
        "        k = sigd.pop('kwargs')\n",
        "        s2 = {k:v for k,v in inspect.signature(to_f).parameters.items()\n",
        "              if v.default != inspect.Parameter.empty and k not in sigd}\n",
        "        sigd.update(s2)\n",
        "        if keep: sigd['kwargs'] = k\n",
        "        from_f.__signature__ = sig.replace(parameters=sigd.values())\n",
        "        return f\n",
        "    return _f\n",
        "\n",
        "def store_attr(self, nms):\n",
        "    \"Store params named in comma-separated `nms` from calling context into attrs in `self`\"\n",
        "    mod = inspect.currentframe().f_back.f_locals\n",
        "    for n in re.split(', *', nms): setattr(self,n,mod[n])\n",
        "\n",
        "NormType = Enum('NormType', 'Batch BatchZero Weight Spectral Instance InstanceZero')\n",
        "\n",
        "def _conv_func(ndim=2, transpose=False):\n",
        "    \"Return the proper conv `ndim` function, potentially `transposed`.\"\n",
        "    assert 1 <= ndim <=3\n",
        "    return getattr(nn, f'Conv{\"Transpose\" if transpose else \"\"}{ndim}d')\n",
        "\n",
        "def init_default(m, func=nn.init.kaiming_normal_):\n",
        "    \"Initialize `m` weights with `func` and set `bias` to 0.\"\n",
        "    if func and hasattr(m, 'weight'): func(m.weight)\n",
        "    with torch.no_grad():\n",
        "        if getattr(m, 'bias', None) is not None: m.bias.fill_(0.)\n",
        "    return m\n",
        "    \n",
        "def _get_norm(prefix, nf, ndim=2, zero=False, **kwargs):\n",
        "    \"Norm layer with `nf` features and `ndim` initialized depending on `norm_type`.\"\n",
        "    assert 1 <= ndim <= 3\n",
        "    bn = getattr(nn, f\"{prefix}{ndim}d\")(nf, **kwargs)\n",
        "    if bn.affine:\n",
        "        bn.bias.data.fill_(1e-3)\n",
        "        bn.weight.data.fill_(0. if zero else 1.)\n",
        "    return bn \n",
        "\n",
        "def BatchNorm(nf, ndim=2, norm_type=NormType.Batch, **kwargs):\n",
        "    \"BatchNorm layer with `nf` features and `ndim` initialized depending on `norm_type`.\"\n",
        "    return _get_norm('BatchNorm', nf, ndim, zero=norm_type==NormType.BatchZero, **kwargs)\n",
        "\n",
        "class ConvLayer(nn.Sequential):\n",
        "    \"Create a sequence of convolutional (`ni` to `nf`), ReLU (if `use_activ`) and `norm_type` layers.\"\n",
        "    def __init__(self, ni, nf, ks=3, stride=1, padding=None, bias=None, ndim=2, norm_type=NormType.Batch, bn_1st=True,\n",
        "                 act_cls=nn.ReLU, transpose=False, init=nn.init.kaiming_normal_, xtra=None, **kwargs):\n",
        "        if padding is None: padding = ((ks-1)//2 if not transpose else 0)\n",
        "        bn = norm_type in (NormType.Batch, NormType.BatchZero)\n",
        "        inn = norm_type in (NormType.Instance, NormType.InstanceZero)\n",
        "        if bias is None: bias = not (bn or inn)\n",
        "        conv_func = _conv_func(ndim, transpose=transpose)\n",
        "        conv = init_default(conv_func(ni, nf, kernel_size=ks, bias=bias, stride=stride, padding=padding, **kwargs), init)\n",
        "        if   norm_type==NormType.Weight:   conv = weight_norm(conv)\n",
        "        elif norm_type==NormType.Spectral: conv = spectral_norm(conv)\n",
        "        layers = [conv]\n",
        "        act_bn = []\n",
        "        if act_cls is not None: act_bn.append(act_cls())\n",
        "        if bn: act_bn.append(BatchNorm(nf, norm_type=norm_type, ndim=ndim))\n",
        "        if inn: act_bn.append(InstanceNorm(nf, norm_type=norm_type, ndim=ndim))\n",
        "        if bn_1st: act_bn.reverse()\n",
        "        layers += act_bn\n",
        "        if xtra: layers.append(xtra)\n",
        "        super().__init__(*layers)\n",
        "\n",
        "def AdaptiveAvgPool(sz=1, ndim=2):\n",
        "    \"nn.AdaptiveAvgPool layer for `ndim`\"\n",
        "    assert 1 <= ndim <= 3\n",
        "    return getattr(nn, f\"AdaptiveAvgPool{ndim}d\")(sz)\n",
        "\n",
        "def MaxPool(ks=2, stride=None, padding=0, ndim=2, ceil_mode=False):\n",
        "    \"nn.MaxPool layer for `ndim`\"\n",
        "    assert 1 <= ndim <= 3\n",
        "    return getattr(nn, f\"MaxPool{ndim}d\")(ks, stride=stride, padding=padding)\n",
        "\n",
        "def AvgPool(ks=2, stride=None, padding=0, ndim=2, ceil_mode=False):\n",
        "    \"nn.AvgPool layer for `ndim`\"\n",
        "    assert 1 <= ndim <= 3\n",
        "    return getattr(nn, f\"AvgPool{ndim}d\")(ks, stride=stride, padding=padding, ceil_mode=ceil_mode)\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    \"Resnet block from `ni` to `nh` with `stride`\"\n",
        "    @delegates(ConvLayer.__init__)\n",
        "    def __init__(self, expansion, ni, nf, stride=1, kernel_size=3, groups=1, reduction=None, nh1=None, nh2=None, dw=False, g2=1,\n",
        "                 sa=False, sym=False, norm_type=NormType.Batch, act_cls=nn.ReLU, ndim=2,\n",
        "                 pool=AvgPool, pool_first=True, **kwargs):\n",
        "        super().__init__()\n",
        "        norm2 = (NormType.BatchZero if norm_type==NormType.Batch else\n",
        "                 NormType.InstanceZero if norm_type==NormType.Instance else norm_type)\n",
        "        if nh2 is None: nh2 = nf\n",
        "        if nh1 is None: nh1 = nh2\n",
        "        nf,ni = nf*expansion,ni*expansion\n",
        "        k0 = dict(norm_type=norm_type, act_cls=act_cls, ndim=ndim, **kwargs)\n",
        "        k1 = dict(norm_type=norm2, act_cls=None, ndim=ndim, **kwargs)\n",
        "        layers  = [ConvLayer(ni,  nh2, kernel_size, stride=stride, groups=ni if dw else groups, **k0),\n",
        "                   ConvLayer(nh2,  nf, kernel_size, groups=g2, **k1)\n",
        "        ] if expansion == 1 else [\n",
        "                   ConvLayer(ni,  nh1, 1, **k0),\n",
        "                   ConvLayer(nh1, nh2, kernel_size, stride=stride, groups=nh1 if dw else groups, **k0),\n",
        "                   ConvLayer(nh2,  nf, 1, groups=g2, **k1)]\n",
        "        self.convs = nn.Sequential(*layers)\n",
        "        convpath = [self.convs]\n",
        "        if reduction: convpath.append(SEModule(nf, reduction=reduction, act_cls=act_cls))\n",
        "        if sa: convpath.append(SimpleSelfAttention(nf,ks=1,sym=sym))\n",
        "        self.convpath = nn.Sequential(*convpath)\n",
        "        idpath = []\n",
        "        if ni!=nf: idpath.append(ConvLayer(ni, nf, 1, act_cls=None, ndim=ndim, **kwargs))\n",
        "        if stride!=1: idpath.insert((1,0)[pool_first], pool(2, ndim=ndim, ceil_mode=True))\n",
        "        self.idpath = nn.Sequential(*idpath)\n",
        "        self.act = nn.ReLU(inplace=True) if act_cls is nn.ReLU else act_cls()\n",
        "\n",
        "    def forward(self, x): return self.act(self.convpath(x) + self.idpath(x))\n",
        "\n",
        "######################### adapted from vison.models.xresnet\n",
        "def init_cnn(m):\n",
        "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
        "    if isinstance(m, (nn.Conv1d, nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
        "    for l in m.children(): init_cnn(l)\n",
        "\n",
        "class XResNet1d(nn.Sequential):\n",
        "    @delegates(ResBlock)\n",
        "    def __init__(self, block, expansion, layers, p=0.0, input_channels=3, num_classes=1000, stem_szs=(32,32,64),kernel_size=5,kernel_size_stem=5,\n",
        "                 widen=1.0, sa=False, act_cls=nn.ReLU, lin_ftrs_head=None, ps_head=0.5, bn_final_head=False, bn_head=True, act_head=\"relu\", concat_pooling=True, **kwargs):\n",
        "        store_attr(self, 'block,expansion,act_cls')\n",
        "        stem_szs = [input_channels, *stem_szs]\n",
        "        stem = [ConvLayer(stem_szs[i], stem_szs[i+1], ks=kernel_size_stem, stride=2 if i==0 else 1, act_cls=act_cls, ndim=1)\n",
        "                for i in range(3)]\n",
        "\n",
        "        #block_szs = [int(o*widen) for o in [64,128,256,512] +[256]*(len(layers)-4)]\n",
        "        block_szs = [int(o*widen) for o in [64,64,64,64] +[32]*(len(layers)-4)]\n",
        "        block_szs = [64//expansion] + block_szs\n",
        "        blocks = [self._make_layer(ni=block_szs[i], nf=block_szs[i+1], blocks=l,\n",
        "                                   stride=1 if i==0 else 2, kernel_size=kernel_size, sa=sa and i==len(layers)-4, ndim=1, **kwargs)\n",
        "                  for i,l in enumerate(layers)]\n",
        "\n",
        "        head = create_head1d(block_szs[-1]*expansion, nc=num_classes, lin_ftrs=lin_ftrs_head, ps=ps_head, bn_final=bn_final_head, bn=bn_head, act=act_head, concat_pooling=concat_pooling)\n",
        "        \n",
        "        super().__init__(\n",
        "            *stem, nn.MaxPool1d(kernel_size=3, stride=2, padding=1),\n",
        "            *blocks,\n",
        "            head,\n",
        "        )\n",
        "        init_cnn(self)\n",
        "\n",
        "    def _make_layer(self, ni, nf, blocks, stride, kernel_size, sa, **kwargs):\n",
        "        return nn.Sequential(\n",
        "            *[self.block(self.expansion, ni if i==0 else nf, nf, stride=stride if i==0 else 1,\n",
        "                      kernel_size=kernel_size, sa=sa and i==(blocks-1), act_cls=self.act_cls, **kwargs)\n",
        "              for i in range(blocks)])\n",
        "    \n",
        "    def get_layer_groups(self):\n",
        "        return (self[3],self[-1])\n",
        "    \n",
        "    def get_output_layer(self):\n",
        "        return self[-1][-1]\n",
        "        \n",
        "    def set_output_layer(self,x):\n",
        "        self[-1][-1]=x\n",
        "\n",
        "\n",
        "#xresnets\n",
        "def _xresnet1d(expansion, layers, **kwargs):\n",
        "    return XResNet1d(ResBlock, expansion, layers, **kwargs)\n",
        "    \n",
        "def xresnet1d18 (**kwargs): return _xresnet1d(1, [2, 2,  2, 2], **kwargs)\n",
        "def xresnet1d34 (**kwargs): return _xresnet1d(1, [3, 4,  6, 3], **kwargs)\n",
        "def xresnet1d50 (**kwargs): return _xresnet1d(4, [3, 4,  6, 3], **kwargs)\n",
        "def xresnet1d101(**kwargs): return _xresnet1d(4, [3, 4, 23, 3], **kwargs)\n",
        "def xresnet1d152(**kwargs): return _xresnet1d(4, [3, 8, 36, 3], **kwargs)\n",
        "def xresnet1d18_deep  (**kwargs): return _xresnet1d(1, [2,2,2,2,1,1], **kwargs)\n",
        "def xresnet1d34_deep  (**kwargs): return _xresnet1d(1, [3,4,6,3,1,1], **kwargs)\n",
        "def xresnet1d50_deep  (**kwargs): return _xresnet1d(4, [3,4,6,3,1,1], **kwargs)\n",
        "def xresnet1d18_deeper(**kwargs): return _xresnet1d(1, [2,2,1,1,1,1,1,1], **kwargs)\n",
        "def xresnet1d34_deeper(**kwargs): return _xresnet1d(1, [3,4,6,3,1,1,1,1], **kwargs)\n",
        "def xresnet1d50_deeper(**kwargs): return _xresnet1d(4, [3,4,6,3,1,1,1,1], **kwargs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypHo8c2bLNmD",
        "cellView": "form"
      },
      "source": [
        "#@title Default title text\n",
        "from models.timeseries_utils import *\n",
        "\n",
        "from fastai import *\n",
        "from fastai.basic_data import *\n",
        "from fastai.basic_train import *\n",
        "from fastai.train import *\n",
        "from fastai.metrics import *\n",
        "from fastai.torch_core import *\n",
        "from fastai.callbacks.tracker import SaveModelCallback\n",
        "\n",
        "from pathlib import Path\n",
        "from functools import partial\n",
        "\n",
        "from models.resnet1d import resnet1d18,resnet1d34,resnet1d50,resnet1d101,resnet1d152,resnet1d_wang,resnet1d,wrn1d_22\n",
        "from models.xresnet1d import xresnet1d18,xresnet1d34,xresnet1d50,xresnet1d101,xresnet1d152,xresnet1d18_deep,xresnet1d34_deep,xresnet1d50_deep,xresnet1d18_deeper,xresnet1d34_deeper,xresnet1d50_deeper\n",
        "from models.inception1d import inception1d\n",
        "from models.basic_conv1d import fcn,fcn_wang,schirrmeister,sen,basic1d,weight_init\n",
        "from models.rnn1d import RNN1d\n",
        "import math\n",
        "\n",
        "from models.base_model import ClassificationModel\n",
        "import torch \n",
        "\n",
        "#for lrfind\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#eval for early stopping\n",
        "from fastai.callback import Callback\n",
        "from utils.utils import evaluate_experiment\n",
        "\n",
        "class metric_func(Callback):\n",
        "    \"Obtains score using user-supplied function func (potentially ignoring targets with ignore_idx)\"\n",
        "    def __init__(self, func, name=\"metric_func\", ignore_idx=None, one_hot_encode_target=True, argmax_pred=False, softmax_pred=True, flatten_target=True, sigmoid_pred=False,metric_component=None):\n",
        "        super().__init__()\n",
        "        self.func = func\n",
        "        self.ignore_idx = ignore_idx\n",
        "        self.one_hot_encode_target = one_hot_encode_target\n",
        "        self.argmax_pred = argmax_pred\n",
        "        self.softmax_pred = softmax_pred\n",
        "        self.flatten_target = flatten_target\n",
        "        self.sigmoid_pred = sigmoid_pred\n",
        "        self.metric_component = metric_component\n",
        "        self.name=name\n",
        "\n",
        "    def on_epoch_begin(self, **kwargs):\n",
        "        self.y_pred = None\n",
        "        self.y_true = None\n",
        "    \n",
        "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
        "        #flatten everything (to make it also work for annotation tasks)\n",
        "        y_pred_flat = last_output.view((-1,last_output.size()[-1]))\n",
        "        \n",
        "        if(self.flatten_target):\n",
        "            y_true_flat = last_target.view(-1)\n",
        "        y_true_flat = last_target\n",
        "\n",
        "        #optionally take argmax of predictions\n",
        "        if(self.argmax_pred is True):\n",
        "            y_pred_flat = y_pred_flat.argmax(dim=1)\n",
        "        elif(self.softmax_pred is True):\n",
        "            y_pred_flat = F.softmax(y_pred_flat, dim=1)\n",
        "        elif(self.sigmoid_pred is True):\n",
        "            y_pred_flat = torch.sigmoid(y_pred_flat)\n",
        "        \n",
        "        #potentially remove ignore_idx entries\n",
        "        if(self.ignore_idx is not None):\n",
        "            selected_indices = (y_true_flat!=self.ignore_idx).nonzero().squeeze()\n",
        "            y_pred_flat = y_pred_flat[selected_indices]\n",
        "            y_true_flat = y_true_flat[selected_indices]\n",
        "        \n",
        "        y_pred_flat = to_np(y_pred_flat)\n",
        "        y_true_flat = to_np(y_true_flat)\n",
        "\n",
        "        if(self.one_hot_encode_target is True):\n",
        "            y_true_flat = one_hot_np(y_true_flat,last_output.size()[-1])\n",
        "\n",
        "        if(self.y_pred is None):\n",
        "            self.y_pred = y_pred_flat\n",
        "            self.y_true = y_true_flat\n",
        "        else:\n",
        "            self.y_pred = np.concatenate([self.y_pred, y_pred_flat], axis=0)\n",
        "            self.y_true = np.concatenate([self.y_true, y_true_flat], axis=0)\n",
        "    \n",
        "    def on_epoch_end(self, last_metrics, **kwargs):\n",
        "        #access full metric (possibly multiple components) via self.metric_complete\n",
        "        self.metric_complete = self.func(self.y_true, self.y_pred)\n",
        "        if(self.metric_component is not None):\n",
        "            return add_metrics(last_metrics, self.metric_complete[self.metric_component])\n",
        "        else:\n",
        "            return add_metrics(last_metrics, self.metric_complete)\n",
        "\n",
        "def fmax_metric(targs,preds):\n",
        "    return evaluate_experiment(targs,preds)[\"Fmax\"]\n",
        "\n",
        "def auc_metric(targs,preds):\n",
        "    return evaluate_experiment(targs,preds)[\"macro_auc\"]\n",
        "\n",
        "def mse_flat(preds,targs):\n",
        "    return torch.mean(torch.pow(preds.view(-1)-targs.view(-1),2))\n",
        "\n",
        "def nll_regression(preds,targs):\n",
        "    #preds: bs, 2\n",
        "    #targs: bs, 1\n",
        "    preds_mean = preds[:,0]\n",
        "    #warning: output goes through exponential map to ensure positivity\n",
        "    preds_var = torch.clamp(torch.exp(preds[:,1]),1e-4,1e10)\n",
        "    #print(to_np(preds_mean)[0],to_np(targs)[0,0],to_np(torch.sqrt(preds_var))[0])\n",
        "    return torch.mean(torch.log(2*math.pi*preds_var)/2) + torch.mean(torch.pow(preds_mean-targs[:,0],2)/2/preds_var)\n",
        "    \n",
        "def nll_regression_init(m):\n",
        "    assert(isinstance(m, nn.Linear))\n",
        "    nn.init.normal_(m.weight,0.,0.001)\n",
        "    nn.init.constant_(m.bias,4)\n",
        "\n",
        "def lr_find_plot(learner, path, filename=\"lr_find\", n_skip=10, n_skip_end=2):\n",
        "    '''saves lr_find plot as file (normally only jupyter output)\n",
        "    on the x-axis is lrs[-1]\n",
        "    '''\n",
        "    learner.lr_find()\n",
        "    \n",
        "    backend_old= matplotlib.get_backend()\n",
        "    plt.switch_backend('agg')\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.xlabel(\"learning rate (log scale)\")\n",
        "    losses = [ to_np(x) for x in learner.recorder.losses[n_skip:-(n_skip_end+1)]]\n",
        "    #print(learner.recorder.val_losses)\n",
        "    #val_losses = [ to_np(x) for x in learner.recorder.val_losses[n_skip:-(n_skip_end+1)]]\n",
        "\n",
        "    plt.plot(learner.recorder.lrs[n_skip:-(n_skip_end+1)],losses )\n",
        "    #plt.plot(learner.recorder.lrs[n_skip:-(n_skip_end+1)],val_losses )\n",
        "\n",
        "    plt.xscale('log')\n",
        "    plt.savefig(str(path/(filename+'.png')))\n",
        "    plt.switch_backend(backend_old)\n",
        "\n",
        "def losses_plot(learner, path, filename=\"losses\", last:int=None):\n",
        "    '''saves lr_find plot as file (normally only jupyter output)\n",
        "    on the x-axis is lrs[-1]\n",
        "    '''\n",
        "    backend_old= matplotlib.get_backend()\n",
        "    plt.switch_backend('agg')\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.xlabel(\"Batches processed\")\n",
        "\n",
        "    last = ifnone(last,len(learner.recorder.nb_batches))\n",
        "    l_b = np.sum(learner.recorder.nb_batches[-last:])\n",
        "    iterations = range_of(learner.recorder.losses)[-l_b:]\n",
        "    plt.plot(iterations, learner.recorder.losses[-l_b:], label='Train')\n",
        "    val_iter = learner.recorder.nb_batches[-last:]\n",
        "    val_iter = np.cumsum(val_iter)+np.sum(learner.recorder.nb_batches[:-last])\n",
        "    plt.plot(val_iter, learner.recorder.val_losses[-last:], label='Validation')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.savefig(str(path/(filename+'.png')))\n",
        "    plt.switch_backend(backend_old)\n",
        "\n",
        "class fastai_model(ClassificationModel):\n",
        "    def __init__(self,name,n_classes,freq,outputfolder,input_shape,pretrained=False,input_size=2.5,input_channels=12,chunkify_train=False,chunkify_valid=True,bs=128,ps_head=0.5,lin_ftrs_head=[128],wd=1e-2,epochs=50,lr=1e-2,kernel_size=5,loss=\"binary_cross_entropy\",pretrainedfolder=None,n_classes_pretrained=None,gradual_unfreezing=True,discriminative_lrs=True,epochs_finetuning=30,early_stopping=None,aggregate_fn=\"max\",concat_train_val=False):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.name = name\n",
        "        self.num_classes = n_classes if loss!= \"nll_regression\" else 2\n",
        "        self.target_fs = freq\n",
        "        self.outputfolder = Path(outputfolder)\n",
        "\n",
        "        self.input_size=int(input_size*self.target_fs)\n",
        "        self.input_channels=input_channels\n",
        "\n",
        "        self.chunkify_train=chunkify_train\n",
        "        self.chunkify_valid=chunkify_valid\n",
        "\n",
        "        self.chunk_length_train=2*self.input_size#target_fs*6\n",
        "        self.chunk_length_valid=self.input_size\n",
        "\n",
        "        self.min_chunk_length=self.input_size#chunk_length\n",
        "\n",
        "        self.stride_length_train=self.input_size#chunk_length_train//8\n",
        "        self.stride_length_valid=self.input_size//2#chunk_length_valid\n",
        "\n",
        "        self.copies_valid = 0 #>0 should only be used with chunkify_valid=False\n",
        "        \n",
        "        self.bs=bs\n",
        "        self.ps_head=ps_head\n",
        "        self.lin_ftrs_head=lin_ftrs_head\n",
        "        self.wd=wd\n",
        "        self.epochs=epochs\n",
        "        self.lr=lr\n",
        "        self.kernel_size = kernel_size\n",
        "        self.loss = loss\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "        if pretrained == True:\n",
        "            if(pretrainedfolder is None):\n",
        "                pretrainedfolder = Path('../output/exp0/models/'+name.split(\"_pretrained\")[0]+'/')\n",
        "            if(n_classes_pretrained is None):\n",
        "                n_classes_pretrained = 71\n",
        "  \n",
        "        self.pretrainedfolder = None if pretrainedfolder is None else Path(pretrainedfolder)\n",
        "        self.n_classes_pretrained = n_classes_pretrained\n",
        "        self.discriminative_lrs = discriminative_lrs\n",
        "        self.gradual_unfreezing = gradual_unfreezing\n",
        "        self.epochs_finetuning = epochs_finetuning\n",
        "\n",
        "        self.early_stopping = early_stopping\n",
        "        self.aggregate_fn = aggregate_fn\n",
        "        self.concat_train_val = concat_train_val\n",
        "\n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "        #convert everything to float32\n",
        "        X_train = [l.astype(np.float32) for l in X_train]\n",
        "        X_val = [l.astype(np.float32) for l in X_val]\n",
        "        y_train = [l.astype(np.float32) for l in y_train]\n",
        "        y_val = [l.astype(np.float32) for l in y_val]\n",
        "\n",
        "        if(self.concat_train_val):\n",
        "            X_train += X_val\n",
        "            y_train += y_val\n",
        "        \n",
        "        if(self.pretrainedfolder is None): #from scratch\n",
        "            print(\"Training from scratch...\")\n",
        "            learn = self._get_learner(X_train,y_train,X_val,y_val)\n",
        "            \n",
        "            #if(self.discriminative_lrs):\n",
        "            #    layer_groups=learn.model.get_layer_groups()\n",
        "            #    learn.split(layer_groups)\n",
        "            learn.model.apply(weight_init)\n",
        "            \n",
        "            #initialization for regression output\n",
        "            if(self.loss==\"nll_regression\" or self.loss==\"mse\"):\n",
        "                output_layer_new = learn.model.get_output_layer()\n",
        "                output_layer_new.apply(nll_regression_init)\n",
        "                learn.model.set_output_layer(output_layer_new)\n",
        "            \n",
        "            lr_find_plot(learn, self.outputfolder)    \n",
        "            learn.fit_one_cycle(self.epochs,self.lr)#slice(self.lr) if self.discriminative_lrs else self.lr)\n",
        "            losses_plot(learn, self.outputfolder)\n",
        "        else: #finetuning\n",
        "            print(\"Finetuning...\")\n",
        "            #create learner\n",
        "            learn = self._get_learner(X_train,y_train,X_val,y_val,self.n_classes_pretrained)\n",
        "            \n",
        "            #load pretrained model\n",
        "            learn.path = self.pretrainedfolder\n",
        "            learn.load(self.pretrainedfolder.stem)\n",
        "            learn.path = self.outputfolder\n",
        "\n",
        "            #exchange top layer\n",
        "            output_layer = learn.model.get_output_layer()\n",
        "            output_layer_new = nn.Linear(output_layer.in_features,self.num_classes).cuda()\n",
        "            apply_init(output_layer_new, nn.init.kaiming_normal_)\n",
        "            learn.model.set_output_layer(output_layer_new)\n",
        "            \n",
        "            #layer groups\n",
        "            if(self.discriminative_lrs):\n",
        "                layer_groups=learn.model.get_layer_groups()\n",
        "                learn.split(layer_groups)\n",
        "\n",
        "            learn.train_bn = True #make sure if bn mode is train\n",
        "            \n",
        "            \n",
        "            #train\n",
        "            lr = self.lr\n",
        "            if(self.gradual_unfreezing):\n",
        "                assert(self.discriminative_lrs is True)\n",
        "                learn.freeze()\n",
        "                lr_find_plot(learn, self.outputfolder,\"lr_find0\")\n",
        "                learn.fit_one_cycle(self.epochs_finetuning,lr)\n",
        "                losses_plot(learn, self.outputfolder,\"losses0\")\n",
        "                #for n in [0]:#range(len(layer_groups)):\n",
        "                #    learn.freeze_to(-n-1)\n",
        "                #    lr_find_plot(learn, self.outputfolder,\"lr_find\"+str(n))\n",
        "                #    learn.fit_one_cycle(self.epochs_gradual_unfreezing,slice(lr))\n",
        "                #    losses_plot(learn, self.outputfolder,\"losses\"+str(n))\n",
        "                    #if(n==0):#reduce lr after first step\n",
        "                    #    lr/=10.\n",
        "                    #if(n>0 and (self.name.startswith(\"fastai_lstm\") or self.name.startswith(\"fastai_gru\"))):#reduce lr further for RNNs\n",
        "                    #    lr/=10\n",
        "                    \n",
        "            learn.unfreeze()\n",
        "            lr_find_plot(learn, self.outputfolder,\"lr_find\"+str(len(layer_groups)))\n",
        "            learn.fit_one_cycle(self.epochs_finetuning,slice(lr/1000,lr/10))\n",
        "            losses_plot(learn, self.outputfolder,\"losses\"+str(len(layer_groups)))\n",
        "\n",
        "        learn.save(self.name) #even for early stopping the best model will have been loaded again\n",
        "    \n",
        "    def predict(self, X):\n",
        "        X = [l.astype(np.float32) for l in X]\n",
        "        y_dummy = [np.ones(self.num_classes,dtype=np.float32) for _ in range(len(X))]\n",
        "        \n",
        "        learn = self._get_learner(X,y_dummy,X,y_dummy)\n",
        "        learn.load(self.name)\n",
        "        \n",
        "        preds,targs=learn.get_preds()\n",
        "        preds=to_np(preds)\n",
        "        \n",
        "        idmap=learn.data.valid_ds.get_id_mapping()\n",
        "\n",
        "        return aggregate_predictions(preds,idmap=idmap,aggregate_fn = np.mean if self.aggregate_fn==\"mean\" else np.amax)  \n",
        "        \n",
        "    def _get_learner(self, X_train,y_train,X_val,y_val,num_classes=None):\n",
        "        df_train = pd.DataFrame({\"data\":range(len(X_train)),\"label\":y_train})\n",
        "        df_valid = pd.DataFrame({\"data\":range(len(X_val)),\"label\":y_val})\n",
        "        \n",
        "        tfms_ptb_xl = [ToTensor()]\n",
        "                \n",
        "        ds_train=TimeseriesDatasetCrops(df_train,self.input_size,num_classes=self.num_classes,chunk_length=self.chunk_length_train if self.chunkify_train else 0,min_chunk_length=self.min_chunk_length,stride=self.stride_length_train,transforms=tfms_ptb_xl,annotation=False,col_lbl =\"label\",npy_data=X_train)\n",
        "        ds_valid=TimeseriesDatasetCrops(df_valid,self.input_size,num_classes=self.num_classes,chunk_length=self.chunk_length_valid if self.chunkify_valid else 0,min_chunk_length=self.min_chunk_length,stride=self.stride_length_valid,transforms=tfms_ptb_xl,annotation=False,col_lbl =\"label\",npy_data=X_val)\n",
        "    \n",
        "        db = DataBunch.create(ds_train,ds_valid,bs=self.bs)\n",
        "\n",
        "        if(self.loss == \"binary_cross_entropy\"):\n",
        "            loss = F.binary_cross_entropy_with_logits\n",
        "        elif(self.loss == \"cross_entropy\"):\n",
        "            loss = F.cross_entropy\n",
        "        elif(self.loss == \"mse\"):\n",
        "            loss = mse_flat\n",
        "        elif(self.loss == \"nll_regression\"):\n",
        "            loss = nll_regression    \n",
        "        else:\n",
        "            print(\"loss not found\")\n",
        "            assert(True)   \n",
        "               \n",
        "        self.input_channels = self.input_shape[-1]\n",
        "        metrics = []\n",
        "\n",
        "        print(\"model:\",self.name) #note: all models of a particular kind share the same prefix but potentially a different postfix such as _input256\n",
        "        num_classes = self.num_classes if num_classes is None else num_classes\n",
        "        #resnet resnet1d18,resnet1d34,resnet1d50,resnet1d101,resnet1d152,resnet1d_wang,resnet1d,wrn1d_22\n",
        "        if(self.name.startswith(\"fastai_resnet1d18\")):\n",
        "            model = resnet1d18(num_classes=num_classes,input_channels=self.input_channels,inplanes=128,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_resnet1d34\")):\n",
        "            model = resnet1d34(num_classes=num_classes,input_channels=self.input_channels,inplanes=128,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_resnet1d50\")):\n",
        "            model = resnet1d50(num_classes=num_classes,input_channels=self.input_channels,inplanes=128,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_resnet1d101\")):\n",
        "            model = resnet1d101(num_classes=num_classes,input_channels=self.input_channels,inplanes=128,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_resnet1d152\")):\n",
        "            model = resnet1d152(num_classes=num_classes,input_channels=self.input_channels,inplanes=128,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_resnet1d_wang\")):\n",
        "            model = resnet1d_wang(num_classes=num_classes,input_channels=self.input_channels,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_wrn1d_22\")):    \n",
        "            model = wrn1d_22(num_classes=num_classes,input_channels=self.input_channels,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        \n",
        "        #xresnet ... (order important for string capture)\n",
        "        elif(self.name.startswith(\"fastai_xresnet1d18_deeper\")):\n",
        "            model = xresnet1d18_deeper(num_classes=num_classes,input_channels=self.input_channels,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_xresnet1d34_deeper\")):\n",
        "            model = xresnet1d34_deeper(num_classes=num_classes,input_channels=self.input_channels,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_xresnet1d50_deeper\")):\n",
        "            model = xresnet1d50_deeper(num_classes=num_classes,input_channels=self.input_channels,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_xresnet1d18_deep\")):\n",
        "            model = xresnet1d18_deep(num_classes=num_classes,input_channels=self.input_channels,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_xresnet1d34_deep\")):\n",
        "            model = xresnet1d34_deep(num_classes=num_classes,input_channels=self.input_channels,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_xresnet1d50_deep\")):\n",
        "            model = xresnet1d50_deep(num_classes=num_classes,input_channels=self.input_channels,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_xresnet1d18\")):\n",
        "            model = xresnet1d18(num_classes=num_classes,input_channels=self.input_channels,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_xresnet1d34\")):\n",
        "            model = xresnet1d34(num_classes=num_classes,input_channels=self.input_channels,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_xresnet1d50\")):\n",
        "            model = xresnet1d50(num_classes=num_classes,input_channels=self.input_channels,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_xresnet1d101\")):\n",
        "            model = xresnet1d101(num_classes=num_classes,input_channels=self.input_channels,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_xresnet1d152\")):\n",
        "            model = xresnet1d152(num_classes=num_classes,input_channels=self.input_channels,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "                        \n",
        "        #inception\n",
        "        #passing the default kernel size of 5 leads to a max kernel size of 40-1 in the inception model as proposed in the original paper\n",
        "        elif(self.name == \"fastai_inception1d_no_residual\"):#note: order important for string capture\n",
        "            model = inception1d(num_classes=num_classes,input_channels=self.input_channels,use_residual=False,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head,kernel_size=8*self.kernel_size)\n",
        "        elif(self.name.startswith(\"fastai_inception1d\")):\n",
        "            model = inception1d(num_classes=num_classes,input_channels=self.input_channels,use_residual=True,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head,kernel_size=8*self.kernel_size)\n",
        "\n",
        "\n",
        "        #basic_conv1d fcn,fcn_wang,schirrmeister,sen,basic1d\n",
        "        elif(self.name.startswith(\"fastai_fcn_wang\")):#note: order important for string capture\n",
        "            model = fcn_wang(num_classes=num_classes,input_channels=self.input_channels,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_fcn\")):\n",
        "            model = fcn(num_classes=num_classes,input_channels=self.input_channels)\n",
        "        elif(self.name.startswith(\"fastai_schirrmeister\")):\n",
        "            model = schirrmeister(num_classes=num_classes,input_channels=self.input_channels,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_sen\")):\n",
        "            model = sen(num_classes=num_classes,input_channels=self.input_channels,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_basic1d\")):    \n",
        "            model = basic1d(num_classes=num_classes,input_channels=self.input_channels,kernel_size=self.kernel_size,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        #RNN\n",
        "        elif(self.name.startswith(\"fastai_lstm_bidir\")):\n",
        "            model = RNN1d(input_channels=self.input_channels,num_classes=num_classes,lstm=True,bidirectional=True,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_gru_bidir\")):\n",
        "            model = RNN1d(input_channels=self.input_channels,num_classes=num_classes,lstm=False,bidirectional=True,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_lstm\")):\n",
        "            model = RNN1d(input_channels=self.input_channels,num_classes=num_classes,lstm=True,bidirectional=False,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        elif(self.name.startswith(\"fastai_gru\")):\n",
        "            model = RNN1d(input_channels=self.input_channels,num_classes=num_classes,lstm=False,bidirectional=False,ps_head=self.ps_head,lin_ftrs_head=self.lin_ftrs_head)\n",
        "        else:\n",
        "            print(\"Model not found.\")\n",
        "            assert(True)\n",
        "            \n",
        "        learn = Learner(db,model, loss_func=loss, metrics=metrics,wd=self.wd,path=self.outputfolder)\n",
        "        \n",
        "        if(self.name.startswith(\"fastai_lstm\") or self.name.startswith(\"fastai_gru\")):\n",
        "            learn.callback_fns.append(partial(GradientClipping, clip=0.25))\n",
        "\n",
        "        if(self.early_stopping is not None):\n",
        "            #supported options: valid_loss, macro_auc, fmax\n",
        "            if(self.early_stopping == \"macro_auc\" and self.loss != \"mse\" and self.loss !=\"nll_regression\"):\n",
        "                metric = metric_func(auc_metric, self.early_stopping, one_hot_encode_target=False, argmax_pred=False, softmax_pred=False, sigmoid_pred=True, flatten_target=False)\n",
        "                learn.metrics.append(metric)\n",
        "                learn.callback_fns.append(partial(SaveModelCallback, monitor=self.early_stopping, every='improvement', name=self.name))\n",
        "            elif(self.early_stopping == \"fmax\" and self.loss != \"mse\" and self.loss !=\"nll_regression\"):\n",
        "                metric = metric_func(fmax_metric, self.early_stopping, one_hot_encode_target=False, argmax_pred=False, softmax_pred=False, sigmoid_pred=True, flatten_target=False)\n",
        "                learn.metrics.append(metric)\n",
        "                learn.callback_fns.append(partial(SaveModelCallback, monitor=self.early_stopping, every='improvement', name=self.name))\n",
        "            elif(self.early_stopping == \"valid_loss\"):\n",
        "                learn.callback_fns.append(partial(SaveModelCallback, monitor=self.early_stopping, every='improvement', name=self.name))\n",
        "            \n",
        "        return learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-05WEAGL1Cv0",
        "cellView": "code"
      },
      "source": [
        "#@title SCP_Experiment definition\n",
        "from utils import utils\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "from itertools import repeat\n",
        "\n",
        "class SCP_Experiment():\n",
        "    '''\n",
        "        Experiment on SCP-ECG statements. All experiments based on SCP are performed and evaluated the same way.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, experiment_name, task, datafolder, outputfolder, models, sampling_frequency=100, min_samples=0, train_fold=8, val_fold=9, test_fold=10, folds_type='strat'):\n",
        "        self.models = models\n",
        "        self.min_samples = min_samples\n",
        "        self.task = task\n",
        "        self.train_fold = train_fold\n",
        "        self.val_fold = val_fold\n",
        "        self.test_fold = test_fold\n",
        "        self.folds_type = folds_type\n",
        "        self.experiment_name = experiment_name\n",
        "        self.outputfolder = outputfolder\n",
        "        self.datafolder = datafolder\n",
        "        self.sampling_frequency = sampling_frequency\n",
        "\n",
        "        # create folder structure if needed\n",
        "        if not os.path.exists(self.outputfolder+self.experiment_name):\n",
        "            os.makedirs(self.outputfolder+self.experiment_name)\n",
        "            if not os.path.exists(self.outputfolder+self.experiment_name+'/results/'):\n",
        "                os.makedirs(self.outputfolder+self.experiment_name+'/results/')\n",
        "            if not os.path.exists(outputfolder+self.experiment_name+'/models/'):\n",
        "                os.makedirs(self.outputfolder+self.experiment_name+'/models/')\n",
        "            if not os.path.exists(outputfolder+self.experiment_name+'/data/'):\n",
        "                os.makedirs(self.outputfolder+self.experiment_name+'/data/')\n",
        "\n",
        "    def prepare(self):\n",
        "        # Load PTB-XL data\n",
        "        self.data, self.raw_labels = utils.load_dataset(self.datafolder, self.sampling_frequency)\n",
        "\n",
        "        # Preprocess label data\n",
        "        self.labels = utils.compute_label_aggregations(self.raw_labels, self.datafolder, self.task)\n",
        "\n",
        "        # Select relevant data and convert to one-hot\n",
        "        self.data, self.labels, self.Y, _ = utils.select_data(self.data, self.labels, self.task, self.min_samples, self.outputfolder+self.experiment_name+'/data/')\n",
        "        self.input_shape = self.data[0].shape\n",
        "        \n",
        "        # 10th fold for testing (9th for now)\n",
        "        self.X_test = self.data[self.labels.strat_fold == self.test_fold]\n",
        "        self.y_test = self.Y[self.labels.strat_fold == self.test_fold]\n",
        "        # 9th fold for validation (8th for now)\n",
        "        self.X_val = self.data[self.labels.strat_fold == self.val_fold]\n",
        "        self.y_val = self.Y[self.labels.strat_fold == self.val_fold]\n",
        "        # rest for training\n",
        "        self.X_train = self.data[self.labels.strat_fold <= self.train_fold]\n",
        "        self.y_train = self.Y[self.labels.strat_fold <= self.train_fold]\n",
        "\n",
        "\n",
        "        # Preprocess signal data\n",
        "        self.X_train, self.X_val, self.X_test = utils.preprocess_signals(self.X_train, self.X_val, self.X_test, self.outputfolder+self.experiment_name+'/data/')\n",
        "        self.n_classes = self.y_train.shape[1]\n",
        "\n",
        "        # save train and test labels\n",
        "        self.y_train.dump(self.outputfolder + self.experiment_name+ '/data/y_train.npy')\n",
        "        self.y_val.dump(self.outputfolder + self.experiment_name+ '/data/y_val.npy')\n",
        "        self.y_test.dump(self.outputfolder + self.experiment_name+ '/data/y_test.npy')\n",
        "\n",
        "        modelname = 'naive'\n",
        "        # create most naive predictions via simple mean in training\n",
        "        mpath = self.outputfolder+self.experiment_name+'/models/'+modelname+'/'\n",
        "        # create folder for model outputs\n",
        "        if not os.path.exists(mpath):\n",
        "            os.makedirs(mpath)\n",
        "        if not os.path.exists(mpath+'results/'):\n",
        "            os.makedirs(mpath+'results/')\n",
        "\n",
        "        mean_y = np.mean(self.y_train, axis=0)\n",
        "        np.array([mean_y]*len(self.y_train)).dump(mpath + 'y_train_pred.npy')\n",
        "        np.array([mean_y]*len(self.y_test)).dump(mpath + 'y_test_pred.npy')\n",
        "        np.array([mean_y]*len(self.y_val)).dump(mpath + 'y_val_pred.npy')\n",
        "\n",
        "    def perform(self):\n",
        "\n",
        "        for model_description in self.models:\n",
        "            modelname = model_description['modelname']\n",
        "            modeltype = model_description['modeltype']\n",
        "            modelparams = model_description['parameters']\n",
        "\n",
        "            mpath = self.outputfolder+self.experiment_name+'/models/'+modelname+'/'\n",
        "            # create folder for model outputs\n",
        "            if not os.path.exists(mpath):\n",
        "                os.makedirs(mpath)\n",
        "            if not os.path.exists(mpath+'results/'):\n",
        "                os.makedirs(mpath+'results/')\n",
        "\n",
        "            n_classes = self.Y.shape[1]\n",
        "            # load respective model\n",
        "            if modeltype == 'WAVELET':\n",
        "                from models.wavelet import WaveletModel\n",
        "                model = WaveletModel(modelname, n_classes, self.sampling_frequency, mpath, self.input_shape, **modelparams)\n",
        "            elif modeltype == \"fastai_model\":\n",
        "                from models.fastai_model import fastai_model\n",
        "                model = fastai_model(modelname, n_classes, self.sampling_frequency, mpath, self.input_shape, **modelparams)\n",
        "            elif modeltype == \"YOUR_MODEL_TYPE\":\n",
        "                # YOUR MODEL GOES HERE!\n",
        "                from models.your_model import YourModel\n",
        "                model = YourModel(modelname, n_classes, self.sampling_frequency, mpath, self.input_shape, **modelparams)\n",
        "            else:\n",
        "                assert(True)\n",
        "                break\n",
        "\n",
        "            # fit model\n",
        "            model.fit(self.X_train, self.y_train, self.X_val, self.y_val)\n",
        "            # predict and dump\n",
        "            model.predict(self.X_train).dump(mpath+'y_train_pred.npy')\n",
        "            model.predict(self.X_val).dump(mpath+'y_val_pred.npy')\n",
        "            model.predict(self.X_test).dump(mpath+'y_test_pred.npy')\n",
        "\n",
        "        modelname = 'ensemble'\n",
        "        # create ensemble predictions via simple mean across model predictions (except naive predictions)\n",
        "        ensemblepath = self.outputfolder+self.experiment_name+'/models/'+modelname+'/'\n",
        "        # create folder for model outputs\n",
        "        if not os.path.exists(ensemblepath):\n",
        "            os.makedirs(ensemblepath)\n",
        "        if not os.path.exists(ensemblepath+'results/'):\n",
        "            os.makedirs(ensemblepath+'results/')\n",
        "        # load all predictions\n",
        "        ensemble_train, ensemble_val, ensemble_test = [],[],[]\n",
        "        for model_description in os.listdir(self.outputfolder+self.experiment_name+'/models/'):\n",
        "            if not model_description in ['ensemble', 'naive']:\n",
        "                mpath = self.outputfolder+self.experiment_name+'/models/'+model_description+'/'\n",
        "                ensemble_train.append(np.load(mpath+'y_train_pred.npy', allow_pickle=True))\n",
        "                ensemble_val.append(np.load(mpath+'y_val_pred.npy', allow_pickle=True))\n",
        "                ensemble_test.append(np.load(mpath+'y_test_pred.npy', allow_pickle=True))\n",
        "        # dump mean predictions\n",
        "        np.array(ensemble_train).mean(axis=0).dump(ensemblepath + 'y_train_pred.npy')\n",
        "        np.array(ensemble_test).mean(axis=0).dump(ensemblepath + 'y_test_pred.npy')\n",
        "        np.array(ensemble_val).mean(axis=0).dump(ensemblepath + 'y_val_pred.npy')\n",
        "\n",
        "    def evaluate(self, n_bootstraping_samples=100, n_jobs=20, bootstrap_eval=False, dumped_bootstraps=True):\n",
        "\n",
        "        # get labels\n",
        "        y_train = np.load(self.outputfolder+self.experiment_name+'/data/y_train.npy', allow_pickle=True)\n",
        "        #y_val = np.load(self.outputfolder+self.experiment_name+'/data/y_val.npy', allow_pickle=True)\n",
        "        y_test = np.load(self.outputfolder+self.experiment_name+'/data/y_test.npy', allow_pickle=True)\n",
        "\n",
        "        # if bootstrapping then generate appropriate samples for each\n",
        "        if bootstrap_eval:\n",
        "            if not dumped_bootstraps:\n",
        "                #train_samples = np.array(utils.get_appropriate_bootstrap_samples(y_train, n_bootstraping_samples))\n",
        "                test_samples = np.array(utils.get_appropriate_bootstrap_samples(y_test, n_bootstraping_samples))\n",
        "                #val_samples = np.array(utils.get_appropriate_bootstrap_samples(y_val, n_bootstraping_samples))\n",
        "            else:\n",
        "                test_samples = np.load(self.outputfolder+self.experiment_name+'/test_bootstrap_ids.npy', allow_pickle=True)\n",
        "        else:\n",
        "            #train_samples = np.array([range(len(y_train))])\n",
        "            test_samples = np.array([range(len(y_test))])\n",
        "            #val_samples = np.array([range(len(y_val))])\n",
        "\n",
        "        # store samples for future evaluations\n",
        "        #train_samples.dump(self.outputfolder+self.experiment_name+'/train_bootstrap_ids.npy')\n",
        "        test_samples.dump(self.outputfolder+self.experiment_name+'/test_bootstrap_ids.npy')\n",
        "        #val_samples.dump(self.outputfolder+self.experiment_name+'/val_bootstrap_ids.npy')\n",
        "\n",
        "        # iterate over all models fitted so far\n",
        "        for m in sorted(os.listdir(self.outputfolder+self.experiment_name+'/models')):\n",
        "            print(m)\n",
        "            mpath = self.outputfolder+self.experiment_name+'/models/'+m+'/'\n",
        "            rpath = self.outputfolder+self.experiment_name+'/models/'+m+'/results/'\n",
        "\n",
        "            # load predictions\n",
        "            y_train_pred = np.load(mpath+'y_train_pred.npy', allow_pickle=True)\n",
        "            #y_val_pred = np.load(mpath+'y_val_pred.npy', allow_pickle=True)\n",
        "            y_test_pred = np.load(mpath+'y_test_pred.npy', allow_pickle=True)\n",
        "\n",
        "            if self.experiment_name == 'exp_ICBEB':\n",
        "                # compute classwise thresholds such that recall-focused Gbeta is optimized\n",
        "                thresholds = utils.find_optimal_cutoff_thresholds_for_Gbeta(y_train, y_train_pred)\n",
        "            else:\n",
        "                thresholds = None\n",
        "\n",
        "            pool = multiprocessing.Pool(n_jobs)\n",
        "\n",
        "            # tr_df = pd.concat(pool.starmap(utils.generate_results, zip(train_samples, repeat(y_train), repeat(y_train_pred), repeat(thresholds))))\n",
        "            # tr_df_point = utils.generate_results(range(len(y_train)), y_train, y_train_pred, thresholds)\n",
        "            # tr_df_result = pd.DataFrame(\n",
        "            #     np.array([\n",
        "            #         tr_df_point.mean().values, \n",
        "            #         tr_df.mean().values,\n",
        "            #         tr_df.quantile(0.05).values,\n",
        "            #         tr_df.quantile(0.95).values]), \n",
        "            #     columns=tr_df.columns,\n",
        "            #     index=['point', 'mean', 'lower', 'upper'])\n",
        "\n",
        "            te_df = pd.concat(pool.starmap(utils.generate_results, zip(test_samples, repeat(y_test), repeat(y_test_pred), repeat(thresholds))))\n",
        "            te_df_point = utils.generate_results(range(len(y_test)), y_test, y_test_pred, thresholds)\n",
        "            te_df_result = pd.DataFrame(\n",
        "                np.array([\n",
        "                    te_df_point.mean().values, \n",
        "                    te_df.mean().values,\n",
        "                    te_df.quantile(0.05).values,\n",
        "                    te_df.quantile(0.95).values]), \n",
        "                columns=te_df.columns, \n",
        "                index=['point', 'mean', 'lower', 'upper'])\n",
        "\n",
        "            # val_df = pd.concat(pool.starmap(utils.generate_results, zip(val_samples, repeat(y_val), repeat(y_val_pred), repeat(thresholds))))\n",
        "            # val_df_point = utils.generate_results(range(len(y_val)), y_val, y_val_pred, thresholds)\n",
        "            # val_df_result = pd.DataFrame(\n",
        "            #     np.array([\n",
        "            #         val_df_point.mean().values, \n",
        "            #         val_df.mean().values,\n",
        "            #         val_df.quantile(0.05).values,\n",
        "            #         val_df.quantile(0.95).values]), \n",
        "            #     columns=val_df.columns, \n",
        "            #     index=['point', 'mean', 'lower', 'upper'])\n",
        "\n",
        "            pool.close()\n",
        "\n",
        "            # dump results\n",
        "            #tr_df_result.to_csv(rpath+'tr_results.csv')\n",
        "            #val_df_result.to_csv(rpath+'val_results.csv')\n",
        "            te_df_result.to_csv(rpath+'te_results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmxxCLOWaEjJ"
      },
      "source": [
        "#Training inception-1d on ICBEB\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XOUtXc7GaU3m",
        "outputId": "06758305-bffb-4d00-dfee-9c15b8dcaf37"
      },
      "source": [
        "from experiments.scp_experiment import SCP_Experiment\n",
        "from utils import utils\n",
        "# model configs\n",
        "from configs.fastai_configs import *\n",
        "from configs.wavelet_configs import *\n",
        "\n",
        "\n",
        "def main():\n",
        "    \n",
        "    datafolder_icbeb = '/gdrive/My Drive/ICBEB/'\n",
        "    outputfolder = '../output_ic/'\n",
        "\n",
        "    models = [\n",
        "        # conf_fastai_xresnet1d101,\n",
        "        # conf_fastai_resnet1d_wang,\n",
        "        # conf_fastai_lstm,\n",
        "        # conf_fastai_lstm_bidir,\n",
        "        # conf_fastai_fcn_wang,\n",
        "        conf_fastai_inception1d,\n",
        "        # conf_wavelet_standard_nn,\n",
        "        ]\n",
        "\n",
        "    ##########################################\n",
        "    # EXPERIMENT BASED ICBEB DATA\n",
        "    ##########################################\n",
        "\n",
        "    e = SCP_Experiment('exp_ICBEB', 'all', datafolder_icbeb, outputfolder, models)\n",
        "    e.prepare()\n",
        "    e.perform()\n",
        "    e.evaluate()\n",
        "\n",
        "    # generate greate summary table\n",
        "    utils.ICBEBE_table()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training from scratch...\n",
            "model: fastai_inception1d\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='2' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      66.67% [2/3 00:06<00:03]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.007221</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.730318</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='11' class='' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      26.19% [11/42 00:01<00:02 1.8979]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.848993</td>\n",
              "      <td>0.671847</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.757463</td>\n",
              "      <td>0.607128</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.664204</td>\n",
              "      <td>0.487648</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.535130</td>\n",
              "      <td>0.343341</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.389285</td>\n",
              "      <td>0.283924</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.290825</td>\n",
              "      <td>0.246952</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.237249</td>\n",
              "      <td>0.236148</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.210529</td>\n",
              "      <td>0.218342</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.191919</td>\n",
              "      <td>0.193988</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.177441</td>\n",
              "      <td>0.187097</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.169312</td>\n",
              "      <td>0.191104</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.162654</td>\n",
              "      <td>0.187351</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.157029</td>\n",
              "      <td>0.181249</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.157362</td>\n",
              "      <td>0.185246</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.156224</td>\n",
              "      <td>0.176748</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.152538</td>\n",
              "      <td>0.169842</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.150980</td>\n",
              "      <td>0.171186</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.148890</td>\n",
              "      <td>0.184852</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.145861</td>\n",
              "      <td>0.201523</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.145366</td>\n",
              "      <td>0.169480</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.140873</td>\n",
              "      <td>0.185389</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.139262</td>\n",
              "      <td>0.167941</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.138123</td>\n",
              "      <td>0.169549</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.134682</td>\n",
              "      <td>0.188809</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.131933</td>\n",
              "      <td>0.159628</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.129066</td>\n",
              "      <td>0.168292</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.125732</td>\n",
              "      <td>0.162714</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.122153</td>\n",
              "      <td>0.168987</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.119144</td>\n",
              "      <td>0.171999</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.116088</td>\n",
              "      <td>0.168338</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.115181</td>\n",
              "      <td>0.161157</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.112968</td>\n",
              "      <td>0.162764</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.108408</td>\n",
              "      <td>0.153513</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.103012</td>\n",
              "      <td>0.169164</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.098903</td>\n",
              "      <td>0.167887</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.095880</td>\n",
              "      <td>0.162601</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.090695</td>\n",
              "      <td>0.160398</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.087152</td>\n",
              "      <td>0.168569</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.085366</td>\n",
              "      <td>0.162470</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.079478</td>\n",
              "      <td>0.160749</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.075353</td>\n",
              "      <td>0.169134</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.072558</td>\n",
              "      <td>0.169176</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.068032</td>\n",
              "      <td>0.170189</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.065907</td>\n",
              "      <td>0.165948</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.064111</td>\n",
              "      <td>0.168433</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.062440</td>\n",
              "      <td>0.170342</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.060140</td>\n",
              "      <td>0.170790</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.059549</td>\n",
              "      <td>0.171759</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.058488</td>\n",
              "      <td>0.169631</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.058143</td>\n",
              "      <td>0.171600</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "model: fastai_inception1d\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "aggregating predictions...\n",
            "model: fastai_inception1d\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "aggregating predictions...\n",
            "model: fastai_inception1d\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "aggregating predictions...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ensemble\n",
            "optimize thresholds with respect to G_beta\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:53<00:00,  5.95s/it]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fastai_inception1d\n",
            "optimize thresholds with respect to G_beta\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:54<00:00,  6.01s/it]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fastai_xresnet1d101\n",
            "optimize thresholds with respect to G_beta\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:53<00:00,  5.94s/it]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "naive\n",
            "optimize thresholds with respect to G_beta\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:51<00:00,  5.75s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1670\u001b[0m                 blocks = [\n\u001b[0;32m-> 1671\u001b[0;31m                     \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1672\u001b[0m                 ]\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    130\u001b[0m             raise ValueError(\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;34mf\"placement implies {len(self.mgr_locs)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 1, placement implies 3",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-cf266997f7a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-cf266997f7a0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# generate greate summary table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mICBEBE_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/gdrive/.shortcut-targets-by-id/1j3ncHY23bba4nXCRAt52Fr8YgGZpml9-/ecg_ptbxl_benchmarking/code/utils/utils.py\u001b[0m in \u001b[0;36mICBEBE_table\u001b[0;34m(selection, folder)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'results_icbeb.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Empty data passed with indices specified."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN4EW3oWaU3p",
        "outputId": "addb7729-e199-455b-c78d-16537e6b200a"
      },
      "source": [
        "y_test_pred = np.load('../output_ic/exp_ICBEB/models/fastai_inception1d/y_test_pred.npy' ,allow_pickle=True)\n",
        "y_test_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(690, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNT0mSlBaU3r",
        "outputId": "1936c0b9-888a-4dd1-a120-74b165a9b3dd"
      },
      "source": [
        "y_test = np.load('../output_ic/exp_ICBEB/data/y_test.npy' ,allow_pickle=True)\n",
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(690, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlFpcBnOaU3s",
        "outputId": "bc9a7c28-24cf-45b8-82b0-301f230ccd70"
      },
      "source": [
        "import numpy as np\n",
        "y_t = np.load('../output_ic/exp_ICBEB/data/y_train.npy' ,allow_pickle=True)\n",
        "y_t.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5497, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "krSEliaCaU3t",
        "outputId": "6d316f55-e188-4311-9ef0-b5ea214553ce"
      },
      "source": [
        "utils.evaluate_experiment(y_test, y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>macro_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.96244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   macro_auc\n",
              "0    0.96244"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKcKYX8JaU3u",
        "outputId": "09a9d9af-038f-4e8e-b9a1-d0ac1ab101a2"
      },
      "source": [
        "y_test[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikKmYayDaU3w",
        "outputId": "92af79b9-3b9d-4bec-9923-e20e8ab2a294"
      },
      "source": [
        "y_test_pred[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.947533e-04, 9.993967e-01, 3.027098e-04, 2.701367e-04, 2.432584e-04, 2.627902e-03, 2.827951e-02, 3.126888e-04,\n",
              "       1.256982e-02], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrAEU2llaU3x",
        "outputId": "4e01d01e-ad91-4582-b359-3dfde50a23e8"
      },
      "source": [
        "from sklearn.metrics import classification_report, fbeta_score, roc_auc_score, roc_curve, roc_curve, auc\n",
        "\n",
        "def find_optimal_cutoff_threshold(target, predicted):\n",
        "    \"\"\" \n",
        "    Find the optimal probability cutoff point for a classification model related to event rate\n",
        "    \"\"\"\n",
        "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
        "    optimal_idx = np.argmax(tpr - fpr)\n",
        "    optimal_threshold = threshold[optimal_idx]\n",
        "    return optimal_threshold\n",
        "\n",
        "def find_optimal_cutoff_thresholds(y_true, y_pred):\n",
        "\treturn [find_optimal_cutoff_threshold(y_true[:,i], y_pred[:,i]) for i in range(y_true.shape[1])]\n",
        "\n",
        "thresholds =  find_optimal_cutoff_thresholds_for_Gbeta(y_test , y_test_pred)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "optimize thresholds with respect to G_beta\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:07<00:00,  1.19it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXIrmNeVaU3z",
        "outputId": "394a05de-ea81-428c-8e61-e7218e6b56c2"
      },
      "source": [
        "y_pred_binary = apply_thresholds(y_test_pred, thresholds)\n",
        "y_pred_binary[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "bKaS4ELqaU30",
        "outputId": "825ad1c7-f51b-4b42-e8d3-77a3f0bfd165"
      },
      "source": [
        "utils.evaluate_experiment(y_test, y_pred_binary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>macro_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.924707</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   macro_auc\n",
              "0   0.924707"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjdXP28jaU31"
      },
      "source": [
        "from sklearn.metrics import (confusion_matrix,\n",
        "                             precision_score, recall_score, f1_score,\n",
        "                             precision_recall_curve, average_precision_score , balanced_accuracy_score , roc_auc_score, accuracy_score)\n",
        "diagnosis = ['NORM', 'AFIB', '1AVB', 'CLBBB', 'CRBBB', 'PAC', 'VPC', 'STD_', 'STE_']\n",
        "def specificity_score(y_true, y_pred):\n",
        "    m = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    spc = m[0, 0] * 1.0 / (m[0, 0] + m[0, 1])\n",
        "    return spc\n",
        "\n",
        "def get_scores(y_true, y_pred, score_fun):\n",
        "    nclasses = np.shape(y_true)[1]\n",
        "    scores = []\n",
        "    for name, fun in score_fun.items():\n",
        "        scores += [[fun(y_true[:, k], y_pred[:, k]) for k in range(nclasses)]]\n",
        "    return np.array(scores).T\n",
        "\n",
        "\n",
        "score_fun = {'Precision': precision_score,\n",
        "             'Recall': recall_score, \n",
        "             'F1 score': f1_score, 'AUC':roc_auc_score , 'accuracy': accuracy_score}\n",
        "\n",
        "scores_list = []\n",
        "for y_pred in [y_pred_binary]:\n",
        "    # Compute scores\n",
        "    scores = get_scores(y_test, y_pred, score_fun)\n",
        "    # Put them into a data frame\n",
        "    scores_df = pd.DataFrame(scores,index=diagnosis, columns=score_fun.keys())\n",
        "    # Append\n",
        "    scores_list.append(scores_df)\n",
        "# Concatenate dataframes\n",
        "scores_all_df = pd.concat(scores_list, axis=1, keys=[''])\n",
        "# Change multiindex levels\n",
        "scores_all_df = scores_all_df.swaplevel(0, 1, axis=1)\n",
        "scores_all_df = scores_all_df.reindex(level=0, columns=score_fun.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "CimhX_acJ3EV",
        "outputId": "59740b38-ee1c-4989-b57c-25f000bd5730"
      },
      "source": [
        "scores_all_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 score</th>\n",
              "      <th>AUC</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NORM</th>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.866242</td>\n",
              "      <td>0.958468</td>\n",
              "      <td>0.969565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFIB</th>\n",
              "      <td>0.900763</td>\n",
              "      <td>0.959350</td>\n",
              "      <td>0.929134</td>\n",
              "      <td>0.968211</td>\n",
              "      <td>0.973913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1AVB</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.996997</td>\n",
              "      <td>0.994203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CLBBB</th>\n",
              "      <td>0.924623</td>\n",
              "      <td>0.953368</td>\n",
              "      <td>0.938776</td>\n",
              "      <td>0.961593</td>\n",
              "      <td>0.965217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CRBBB</th>\n",
              "      <td>0.522293</td>\n",
              "      <td>0.891304</td>\n",
              "      <td>0.658635</td>\n",
              "      <td>0.882943</td>\n",
              "      <td>0.876812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PAC</th>\n",
              "      <td>0.541176</td>\n",
              "      <td>0.754098</td>\n",
              "      <td>0.630137</td>\n",
              "      <td>0.846048</td>\n",
              "      <td>0.921739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VPC</th>\n",
              "      <td>0.757576</td>\n",
              "      <td>0.862069</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>0.911134</td>\n",
              "      <td>0.947826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STD_</th>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.772727</td>\n",
              "      <td>0.693878</td>\n",
              "      <td>0.878879</td>\n",
              "      <td>0.978261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STE_</th>\n",
              "      <td>0.821918</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.839161</td>\n",
              "      <td>0.918088</td>\n",
              "      <td>0.966667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Precision    Recall  F1 score       AUC  accuracy\n",
              "                                                       \n",
              "NORM   0.800000  0.944444  0.866242  0.958468  0.969565\n",
              "AFIB   0.900763  0.959350  0.929134  0.968211  0.973913\n",
              "1AVB   0.857143  1.000000  0.923077  0.996997  0.994203\n",
              "CLBBB  0.924623  0.953368  0.938776  0.961593  0.965217\n",
              "CRBBB  0.522293  0.891304  0.658635  0.882943  0.876812\n",
              "PAC    0.541176  0.754098  0.630137  0.846048  0.921739\n",
              "VPC    0.757576  0.862069  0.806452  0.911134  0.947826\n",
              "STD_   0.629630  0.772727  0.693878  0.878879  0.978261\n",
              "STE_   0.821918  0.857143  0.839161  0.918088  0.966667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "E0XBA2FXBj6V",
        "outputId": "352b79c0-9b6a-4bfc-f421-313ebac548d3"
      },
      "source": [
        "scores_all_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>F1 score</th>\n",
              "      <th>balanced accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NORM</th>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.972492</td>\n",
              "      <td>0.866242</td>\n",
              "      <td>0.958468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFIB</th>\n",
              "      <td>0.900763</td>\n",
              "      <td>0.959350</td>\n",
              "      <td>0.977072</td>\n",
              "      <td>0.929134</td>\n",
              "      <td>0.968211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1AVB</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.993994</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.996997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CLBBB</th>\n",
              "      <td>0.924623</td>\n",
              "      <td>0.953368</td>\n",
              "      <td>0.969819</td>\n",
              "      <td>0.938776</td>\n",
              "      <td>0.961593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CRBBB</th>\n",
              "      <td>0.522293</td>\n",
              "      <td>0.891304</td>\n",
              "      <td>0.874582</td>\n",
              "      <td>0.658635</td>\n",
              "      <td>0.882943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PAC</th>\n",
              "      <td>0.541176</td>\n",
              "      <td>0.754098</td>\n",
              "      <td>0.937997</td>\n",
              "      <td>0.630137</td>\n",
              "      <td>0.846048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VPC</th>\n",
              "      <td>0.757576</td>\n",
              "      <td>0.862069</td>\n",
              "      <td>0.960199</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>0.911134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STD_</th>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.772727</td>\n",
              "      <td>0.985030</td>\n",
              "      <td>0.693878</td>\n",
              "      <td>0.878879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STE_</th>\n",
              "      <td>0.821918</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.979032</td>\n",
              "      <td>0.839161</td>\n",
              "      <td>0.918088</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Precision    Recall Specificity  F1 score balanced accuracy\n",
              "                                                                 \n",
              "NORM   0.800000  0.944444    0.972492  0.866242          0.958468\n",
              "AFIB   0.900763  0.959350    0.977072  0.929134          0.968211\n",
              "1AVB   0.857143  1.000000    0.993994  0.923077          0.996997\n",
              "CLBBB  0.924623  0.953368    0.969819  0.938776          0.961593\n",
              "CRBBB  0.522293  0.891304    0.874582  0.658635          0.882943\n",
              "PAC    0.541176  0.754098    0.937997  0.630137          0.846048\n",
              "VPC    0.757576  0.862069    0.960199  0.806452          0.911134\n",
              "STD_   0.629630  0.772727    0.985030  0.693878          0.878879\n",
              "STE_   0.821918  0.857143    0.979032  0.839161          0.918088"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "dhLZvVOgaU33",
        "outputId": "28542157-8129-4817-84a4-0204741a38ec"
      },
      "source": [
        "# %% Confusion matrices (Supplementary Table 1)\n",
        "from sklearn.metrics import (confusion_matrix,\n",
        "                             precision_score, recall_score, f1_score,\n",
        "                             precision_recall_curve, average_precision_score)\n",
        "\n",
        "import xarray as xr\n",
        "\n",
        "M = [[confusion_matrix(y_test[:, k], y_pred[:, k], labels=[0, 1])\n",
        "      for k in range(9)] for y_pred in [y_pred_binary]]\n",
        "\n",
        "M_xarray = xr.DataArray(np.array(M),\n",
        "                        dims=['predictor', 'diagnosis', 'true label', 'predicted label'],\n",
        "                        coords={'predictor': ['inception-1d'],\n",
        "                                'diagnosis': diagnosis,\n",
        "                                'true label': ['not present', 'present'],\n",
        "                                'predicted label': ['not present', 'present']})\n",
        "confusion_matrices = M_xarray.to_dataframe('n')\n",
        "confusion_matrices = confusion_matrices.reorder_levels([1, 2, 3, 0], axis=0)\n",
        "confusion_matrices = confusion_matrices.unstack()\n",
        "confusion_matrices = confusion_matrices.unstack()\n",
        "confusion_matrices = confusion_matrices['n']\n",
        "confusion_matrices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>predictor</th>\n",
              "      <th colspan=\"2\" halign=\"left\">inception-1d</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>predicted label</th>\n",
              "      <th>not present</th>\n",
              "      <th>present</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diagnosis</th>\n",
              "      <th>true label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">NORM</th>\n",
              "      <th>not present</th>\n",
              "      <td>601</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>4</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">AFIB</th>\n",
              "      <th>not present</th>\n",
              "      <td>554</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>5</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1AVB</th>\n",
              "      <th>not present</th>\n",
              "      <td>662</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">CLBBB</th>\n",
              "      <th>not present</th>\n",
              "      <td>482</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>9</td>\n",
              "      <td>184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">CRBBB</th>\n",
              "      <th>not present</th>\n",
              "      <td>523</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>10</td>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">PAC</th>\n",
              "      <th>not present</th>\n",
              "      <td>590</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>15</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">VPC</th>\n",
              "      <th>not present</th>\n",
              "      <td>579</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>12</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">STD_</th>\n",
              "      <th>not present</th>\n",
              "      <td>658</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">STE_</th>\n",
              "      <th>not present</th>\n",
              "      <td>607</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>10</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "predictor             inception-1d        \n",
              "predicted label        not present present\n",
              "diagnosis true label                      \n",
              "NORM      not present          601      17\n",
              "          present                4      68\n",
              "AFIB      not present          554      13\n",
              "          present                5     118\n",
              "1AVB      not present          662       4\n",
              "          present                0      24\n",
              "CLBBB     not present          482      15\n",
              "          present                9     184\n",
              "CRBBB     not present          523      75\n",
              "          present               10      82\n",
              "PAC       not present          590      39\n",
              "          present               15      46\n",
              "VPC       not present          579      24\n",
              "          present               12      75\n",
              "STD_      not present          658      10\n",
              "          present                5      17\n",
              "STE_      not present          607      13\n",
              "          present               10      60"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0pyjntsjOIt"
      },
      "source": [
        "#Training xResNet1d101 on ICBEB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JrPiKMOVLCEu",
        "outputId": "2bdc4b98-1ab0-4f00-ac06-21861be9a63a"
      },
      "source": [
        "from experiments.scp_experiment import SCP_Experiment\n",
        "from utils import utils\n",
        "# model configs\n",
        "from configs.fastai_configs import *\n",
        "from configs.wavelet_configs import *\n",
        "\n",
        "\n",
        "def main():\n",
        "    \n",
        "    datafolder_icbeb = '/gdrive/My Drive/ICBEB/'\n",
        "    outputfolder = '../output_ic/'\n",
        "\n",
        "    models = [\n",
        "        conf_fastai_xresnet1d101,\n",
        "        # conf_fastai_resnet1d_wang,\n",
        "        # conf_fastai_lstm,\n",
        "        # conf_fastai_lstm_bidir,\n",
        "        # conf_fastai_fcn_wang,\n",
        "        # conf_fastai_inception1d,\n",
        "        # conf_wavelet_standard_nn,\n",
        "        ]\n",
        "\n",
        "    ##########################################\n",
        "    # EXPERIMENT BASED ICBEB DATA\n",
        "    ##########################################\n",
        "\n",
        "    e = SCP_Experiment('exp_ICBEB', 'all', datafolder_icbeb, outputfolder, models)\n",
        "    e.prepare()\n",
        "    e.perform()\n",
        "    e.evaluate()\n",
        "\n",
        "    # generate greate summary table\n",
        "    utils.ICBEBE_table()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training from scratch...\n",
            "model: fastai_xresnet1d101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='2' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      66.67% [2/3 00:10<00:05]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.007873</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.757077</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='11' class='' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      26.19% [11/42 00:01<00:04 2.1940]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.891006</td>\n",
              "      <td>0.915156</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.804841</td>\n",
              "      <td>0.656050</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.712915</td>\n",
              "      <td>0.531988</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.584934</td>\n",
              "      <td>0.459178</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.444187</td>\n",
              "      <td>0.397642</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.356487</td>\n",
              "      <td>0.319240</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.304586</td>\n",
              "      <td>0.272701</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.273903</td>\n",
              "      <td>0.303586</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.247312</td>\n",
              "      <td>0.301600</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.223365</td>\n",
              "      <td>3.883131</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.204966</td>\n",
              "      <td>0.204717</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.189970</td>\n",
              "      <td>0.274000</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.182262</td>\n",
              "      <td>0.185857</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.176588</td>\n",
              "      <td>0.186302</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.169910</td>\n",
              "      <td>0.177580</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.164384</td>\n",
              "      <td>0.198031</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.162820</td>\n",
              "      <td>0.212189</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.159387</td>\n",
              "      <td>0.177385</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.158253</td>\n",
              "      <td>0.197624</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.155276</td>\n",
              "      <td>0.175444</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.153128</td>\n",
              "      <td>0.199732</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.151419</td>\n",
              "      <td>0.195052</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.152039</td>\n",
              "      <td>0.167675</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.150788</td>\n",
              "      <td>0.189218</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.146927</td>\n",
              "      <td>0.194210</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.144589</td>\n",
              "      <td>0.188255</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.144501</td>\n",
              "      <td>0.183887</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.141853</td>\n",
              "      <td>0.172319</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.139849</td>\n",
              "      <td>0.176779</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.138158</td>\n",
              "      <td>0.179347</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.136527</td>\n",
              "      <td>0.211059</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.132855</td>\n",
              "      <td>0.168706</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.129932</td>\n",
              "      <td>0.167382</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.126308</td>\n",
              "      <td>0.171183</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.122560</td>\n",
              "      <td>0.166585</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.121064</td>\n",
              "      <td>0.156784</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.117320</td>\n",
              "      <td>0.162614</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.112911</td>\n",
              "      <td>0.164811</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.110208</td>\n",
              "      <td>0.161105</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.107088</td>\n",
              "      <td>0.161592</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.104013</td>\n",
              "      <td>0.154838</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.099611</td>\n",
              "      <td>0.161553</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.095185</td>\n",
              "      <td>0.162497</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.091862</td>\n",
              "      <td>0.160524</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.089769</td>\n",
              "      <td>0.161229</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.087853</td>\n",
              "      <td>0.160878</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.085002</td>\n",
              "      <td>0.163582</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.084732</td>\n",
              "      <td>0.162777</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.082185</td>\n",
              "      <td>0.163577</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.081682</td>\n",
              "      <td>0.163317</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "model: fastai_xresnet1d101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "aggregating predictions...\n",
            "model: fastai_xresnet1d101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "aggregating predictions...\n",
            "model: fastai_xresnet1d101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "aggregating predictions...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ensemble\n",
            "optimize thresholds with respect to G_beta\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:53<00:00,  5.96s/it]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fastai_xresnet1d101\n",
            "optimize thresholds with respect to G_beta\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:54<00:00,  6.04s/it]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "naive\n",
            "optimize thresholds with respect to G_beta\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:52<00:00,  5.79s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1670\u001b[0m                 blocks = [\n\u001b[0;32m-> 1671\u001b[0;31m                     \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1672\u001b[0m                 ]\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    130\u001b[0m             raise ValueError(\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;34mf\"placement implies {len(self.mgr_locs)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 1, placement implies 3",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-b8768047397f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-b8768047397f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# generate greate summary table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mICBEBE_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/gdrive/MyDrive/ecg_ptbxl_benchmarking/code/utils/utils.py\u001b[0m in \u001b[0;36mICBEBE_table\u001b[0;34m(selection, folder)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'results_icbeb.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Empty data passed with indices specified."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff5A7TVXIB0C",
        "outputId": "4a497b12-80ae-406c-f64e-b51ee8510b89"
      },
      "source": [
        "y_test_pred = np.load('../output_ic/exp_ICBEB/models/fastai_xresnet1d101/y_test_pred.npy' ,allow_pickle=True)\n",
        "y_test_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(690, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc6k7Z4YIB0d",
        "outputId": "b3ca72ed-0930-4068-8f82-c3615a1d8e5c"
      },
      "source": [
        "y_test = np.load('../output_ic/exp_ICBEB/data/y_test.npy' ,allow_pickle=True)\n",
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(690, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnpzujUMvjRS",
        "outputId": "bc9a7c28-24cf-45b8-82b0-301f230ccd70"
      },
      "source": [
        "import numpy as np\n",
        "y_t = np.load('../output_ic/exp_ICBEB/data/y_train.npy' ,allow_pickle=True)\n",
        "y_t.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5497, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "L5l_azvFIB0e",
        "outputId": "7deb4521-6efa-45f1-88cb-42347908890f"
      },
      "source": [
        "utils.evaluate_experiment(y_test, y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>macro_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.969686</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   macro_auc\n",
              "0   0.969686"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tExtJv2qIB0f",
        "outputId": "90f06785-e42a-41f9-de73-db81e4406923"
      },
      "source": [
        "y_test[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw2kk9miIB0f",
        "outputId": "5dc03701-c5b4-4dce-fb8d-b5070c201686"
      },
      "source": [
        "y_test_pred[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.947533e-04, 9.993967e-01, 3.027098e-04, 2.701367e-04, 2.432584e-04, 2.627902e-03, 2.827951e-02, 3.126888e-04,\n",
              "       1.256982e-02], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jckAjljYIB0g",
        "outputId": "a4cce9fe-ab7a-4877-855a-bfe242a15a8e"
      },
      "source": [
        "from sklearn.metrics import classification_report, fbeta_score, roc_auc_score, roc_curve, roc_curve, auc\n",
        "\n",
        "def find_optimal_cutoff_threshold(target, predicted):\n",
        "    \"\"\" \n",
        "    Find the optimal probability cutoff point for a classification model related to event rate\n",
        "    \"\"\"\n",
        "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
        "    optimal_idx = np.argmax(tpr - fpr)\n",
        "    optimal_threshold = threshold[optimal_idx]\n",
        "    return optimal_threshold\n",
        "\n",
        "def find_optimal_cutoff_thresholds(y_true, y_pred):\n",
        "\treturn [find_optimal_cutoff_threshold(y_true[:,i], y_pred[:,i]) for i in range(y_true.shape[1])]\n",
        "\n",
        "thresholds =  find_optimal_cutoff_thresholds_for_Gbeta(y_test , y_test_pred)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "optimize thresholds with respect to G_beta\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:07<00:00,  1.19it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly7e7OwmIB0h",
        "outputId": "7edfccda-c532-4a96-f54d-c3efd91c6338"
      },
      "source": [
        "y_pred_binary = apply_thresholds(y_test_pred, thresholds)\n",
        "y_pred_binary[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "Yb6SPUjhIB0h",
        "outputId": "3e15b78f-7ed7-47e5-829e-11ff8ef96579"
      },
      "source": [
        "utils.evaluate_experiment(y_test, y_pred_binary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>macro_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.920428</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   macro_auc\n",
              "0   0.920428"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXaPBHiPIB0i"
      },
      "source": [
        "from sklearn.metrics import (confusion_matrix,\n",
        "                             precision_score, recall_score, f1_score,\n",
        "                             precision_recall_curve, average_precision_score , accuracy_score , roc_auc_score)\n",
        "diagnosis = ['NORM', 'AFIB', '1AVB', 'CLBBB', 'CRBBB', 'PAC', 'VPC', 'STD_', 'STE_']\n",
        "def specificity_score(y_true, y_pred):\n",
        "    m = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    spc = m[0, 0] * 1.0 / (m[0, 0] + m[0, 1])\n",
        "    return spc\n",
        "\n",
        "def get_scores(y_true, y_pred, score_fun):\n",
        "    nclasses = np.shape(y_true)[1]\n",
        "    scores = []\n",
        "    for name, fun in score_fun.items():\n",
        "        scores += [[fun(y_true[:, k], y_pred[:, k]) for k in range(nclasses)]]\n",
        "    return np.array(scores).T\n",
        "\n",
        "\n",
        "score_fun = {'Precision': precision_score,\n",
        "             'Recall': recall_score,\n",
        "             'F1 score': f1_score ,'AUC':roc_auc_score, 'accuracy': accuracy_score}\n",
        "\n",
        "scores_list = []\n",
        "for y_pred in [y_pred_binary]:\n",
        "    # Compute scores\n",
        "    scores = get_scores(y_test, y_pred, score_fun)\n",
        "    # Put them into a data frame\n",
        "    scores_df = pd.DataFrame(scores,index=diagnosis, columns=score_fun.keys())\n",
        "    # Append\n",
        "    scores_list.append(scores_df)\n",
        "# Concatenate dataframes\n",
        "scores_all_df = pd.concat(scores_list, axis=1, keys=[''])\n",
        "# Change multiindex levels\n",
        "scores_all_df = scores_all_df.swaplevel(0, 1, axis=1)\n",
        "scores_all_df = scores_all_df.reindex(level=0, columns=score_fun.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKfL13dYMRUe",
        "outputId": "bc6a98e4-c0dd-4e6a-aa77-d6955d636e42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "scores_all_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 score</th>\n",
              "      <th>AUC</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NORM</th>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.853659</td>\n",
              "      <td>0.968312</td>\n",
              "      <td>0.965217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFIB</th>\n",
              "      <td>0.934959</td>\n",
              "      <td>0.934959</td>\n",
              "      <td>0.934959</td>\n",
              "      <td>0.960425</td>\n",
              "      <td>0.976812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1AVB</th>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.995495</td>\n",
              "      <td>0.991304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CLBBB</th>\n",
              "      <td>0.907767</td>\n",
              "      <td>0.968912</td>\n",
              "      <td>0.937343</td>\n",
              "      <td>0.965341</td>\n",
              "      <td>0.963768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CRBBB</th>\n",
              "      <td>0.632000</td>\n",
              "      <td>0.858696</td>\n",
              "      <td>0.728111</td>\n",
              "      <td>0.890886</td>\n",
              "      <td>0.914493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PAC</th>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.852459</td>\n",
              "      <td>0.645963</td>\n",
              "      <td>0.888074</td>\n",
              "      <td>0.917391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VPC</th>\n",
              "      <td>0.732673</td>\n",
              "      <td>0.850575</td>\n",
              "      <td>0.787234</td>\n",
              "      <td>0.902899</td>\n",
              "      <td>0.942029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STD_</th>\n",
              "      <td>0.705882</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.768985</td>\n",
              "      <td>0.978261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STE_</th>\n",
              "      <td>0.790123</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.847682</td>\n",
              "      <td>0.943433</td>\n",
              "      <td>0.966667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Precision    Recall  F1 score       AUC  accuracy\n",
              "                                                       \n",
              "NORM   0.760870  0.972222  0.853659  0.968312  0.965217\n",
              "AFIB   0.934959  0.934959  0.934959  0.960425  0.976812\n",
              "1AVB   0.800000  1.000000  0.888889  0.995495  0.991304\n",
              "CLBBB  0.907767  0.968912  0.937343  0.965341  0.963768\n",
              "CRBBB  0.632000  0.858696  0.728111  0.890886  0.914493\n",
              "PAC    0.520000  0.852459  0.645963  0.888074  0.917391\n",
              "VPC    0.732673  0.850575  0.787234  0.902899  0.942029\n",
              "STD_   0.705882  0.545455  0.615385  0.768985  0.978261\n",
              "STE_   0.790123  0.914286  0.847682  0.943433  0.966667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "s1tAoYOYIB0i",
        "outputId": "b405d570-8e94-4898-b85a-963d4b24cdcb"
      },
      "source": [
        "#Gbeta thershold\n",
        "scores_all_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>F1 score</th>\n",
              "      <th>balanced accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NORM</th>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.964401</td>\n",
              "      <td>0.853659</td>\n",
              "      <td>0.968312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFIB</th>\n",
              "      <td>0.934959</td>\n",
              "      <td>0.934959</td>\n",
              "      <td>0.985891</td>\n",
              "      <td>0.934959</td>\n",
              "      <td>0.960425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1AVB</th>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.990991</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.995495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CLBBB</th>\n",
              "      <td>0.907767</td>\n",
              "      <td>0.968912</td>\n",
              "      <td>0.961771</td>\n",
              "      <td>0.937343</td>\n",
              "      <td>0.965341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CRBBB</th>\n",
              "      <td>0.632000</td>\n",
              "      <td>0.858696</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.728111</td>\n",
              "      <td>0.890886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PAC</th>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.852459</td>\n",
              "      <td>0.923688</td>\n",
              "      <td>0.645963</td>\n",
              "      <td>0.888074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VPC</th>\n",
              "      <td>0.732673</td>\n",
              "      <td>0.850575</td>\n",
              "      <td>0.955224</td>\n",
              "      <td>0.787234</td>\n",
              "      <td>0.902899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STD_</th>\n",
              "      <td>0.705882</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.992515</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.768985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STE_</th>\n",
              "      <td>0.790123</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.972581</td>\n",
              "      <td>0.847682</td>\n",
              "      <td>0.943433</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Precision    Recall Specificity  F1 score balanced accuracy\n",
              "                                                                 \n",
              "NORM   0.760870  0.972222    0.964401  0.853659          0.968312\n",
              "AFIB   0.934959  0.934959    0.985891  0.934959          0.960425\n",
              "1AVB   0.800000  1.000000    0.990991  0.888889          0.995495\n",
              "CLBBB  0.907767  0.968912    0.961771  0.937343          0.965341\n",
              "CRBBB  0.632000  0.858696    0.923077  0.728111          0.890886\n",
              "PAC    0.520000  0.852459    0.923688  0.645963          0.888074\n",
              "VPC    0.732673  0.850575    0.955224  0.787234          0.902899\n",
              "STD_   0.705882  0.545455    0.992515  0.615385          0.768985\n",
              "STE_   0.790123  0.914286    0.972581  0.847682          0.943433"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "BLzVCFVhIB0j",
        "outputId": "20bb9768-e37a-427b-efe5-e1485b71fcd8"
      },
      "source": [
        "# %% Confusion matrices (Supplementary Table 1)\n",
        "from sklearn.metrics import (confusion_matrix,\n",
        "                             precision_score, recall_score, f1_score,\n",
        "                             precision_recall_curve, average_precision_score)\n",
        "\n",
        "import xarray as xr\n",
        "\n",
        "M = [[confusion_matrix(y_test[:, k], y_pred[:, k], labels=[0, 1])\n",
        "      for k in range(9)] for y_pred in [y_pred_binary]]\n",
        "\n",
        "M_xarray = xr.DataArray(np.array(M),\n",
        "                        dims=['predictor', 'diagnosis', 'true label', 'predicted label'],\n",
        "                        coords={'predictor': ['xResNet1d-101'],\n",
        "                                'diagnosis': diagnosis,\n",
        "                                'true label': ['not present', 'present'],\n",
        "                                'predicted label': ['not present', 'present']})\n",
        "confusion_matrices = M_xarray.to_dataframe('n')\n",
        "confusion_matrices = confusion_matrices.reorder_levels([1, 2, 3, 0], axis=0)\n",
        "confusion_matrices = confusion_matrices.unstack()\n",
        "confusion_matrices = confusion_matrices.unstack()\n",
        "confusion_matrices = confusion_matrices['n']\n",
        "confusion_matrices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>predictor</th>\n",
              "      <th colspan=\"2\" halign=\"left\">xResNet1d-101</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>predicted label</th>\n",
              "      <th>not present</th>\n",
              "      <th>present</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diagnosis</th>\n",
              "      <th>true label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">NORM</th>\n",
              "      <th>not present</th>\n",
              "      <td>596</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>2</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">AFIB</th>\n",
              "      <th>not present</th>\n",
              "      <td>559</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>8</td>\n",
              "      <td>115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1AVB</th>\n",
              "      <th>not present</th>\n",
              "      <td>660</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">CLBBB</th>\n",
              "      <th>not present</th>\n",
              "      <td>478</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>6</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">CRBBB</th>\n",
              "      <th>not present</th>\n",
              "      <td>552</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>13</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">PAC</th>\n",
              "      <th>not present</th>\n",
              "      <td>581</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>9</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">VPC</th>\n",
              "      <th>not present</th>\n",
              "      <td>576</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>13</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">STD_</th>\n",
              "      <th>not present</th>\n",
              "      <td>663</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">STE_</th>\n",
              "      <th>not present</th>\n",
              "      <td>603</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present</th>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "predictor             xResNet1d-101        \n",
              "predicted label         not present present\n",
              "diagnosis true label                       \n",
              "NORM      not present           596      22\n",
              "          present                 2      70\n",
              "AFIB      not present           559       8\n",
              "          present                 8     115\n",
              "1AVB      not present           660       6\n",
              "          present                 0      24\n",
              "CLBBB     not present           478      19\n",
              "          present                 6     187\n",
              "CRBBB     not present           552      46\n",
              "          present                13      79\n",
              "PAC       not present           581      48\n",
              "          present                 9      52\n",
              "VPC       not present           576      27\n",
              "          present                13      74\n",
              "STD_      not present           663       5\n",
              "          present                10      12\n",
              "STE_      not present           603      17\n",
              "          present                 6      64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJUevd16KUoC"
      },
      "source": [
        "#Finetuning on ICBEB:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jpr0XnGtqWRM",
        "outputId": "d602a095-9924-4c37-ea3f-d18e53fc98ea"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/gdrive/.shortcut-targets-by-id/1j3ncHY23bba4nXCRAt52Fr8YgGZpml9-/ecg_ptbxl_benchmarking/code'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbNorHYoq8rH",
        "outputId": "c6f9bcc1-7d1a-4965-a885-e34d536a43be"
      },
      "source": [
        "cd ecg_ptbxl_benchmarking/code"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/ecg_ptbxl_benchmarking/code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO4FB4Qbxrfj",
        "outputId": "92605713-a483-4486-ec31-3d76483b8589"
      },
      "source": [
        "# from utils import utils\n",
        "\n",
        "sampling_frequency=100\n",
        "datafolder= '/gdrive/My Drive/ICBEB/'\n",
        "task='all'\n",
        "outputfolder='../output0/'\n",
        "\n",
        "# Load data\n",
        "data, raw_labels = utils.load_dataset(datafolder, sampling_frequency)\n",
        "# Preprocess label data\n",
        "labels = utils.compute_label_aggregations(raw_labels, datafolder, task)\n",
        "# Select relevant data and convert to one-hot\n",
        "data, labels, Y, _ = utils.select_data(data, labels, task, min_samples=0, outputfolder=outputfolder)\n",
        "\n",
        "# 1-9 for training \n",
        "X_train = data[labels.strat_fold < 10]\n",
        "y_train = Y[labels.strat_fold < 10]\n",
        "# 10 for validation\n",
        "X_val = data[labels.strat_fold == 10]\n",
        "y_val = Y[labels.strat_fold == 10]\n",
        "\n",
        "num_classes = 9         # <=== number of classes in the finetuning dataset\n",
        "input_shape = [1000,12] # <=== shape of samples, [None, 12] in case of different lengths\n",
        "\n",
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6877/6877 [46:02<00:00,  2.49it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6187,), (6187, 9), (690,), (690, 9))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC8v6EtT17s8"
      },
      "source": [
        "np.save('X_train.npy',X_train)\n",
        "np.save('X_val.npy',X_val)\n",
        "np.save('y_train.npy',y_train)\n",
        "np.save('y_val.npy',y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GzTQZXM2S9i",
        "outputId": "0496c4bf-9146-42ce-fb39-56df2a0fcc17"
      },
      "source": [
        "y_val = np.load('y_val.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "X_val = np.load('X_val.npy', allow_pickle=True)\n",
        "X_train = np.load('X_train.npy', allow_pickle=True)\n",
        "\n",
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6187,), (6187, 9), (690,), (690, 9))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxfT8OKac8vC",
        "outputId": "3cee13c0-cd1e-431a-c9ef-85a16b179c66"
      },
      "source": [
        "X_train[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtV-zMEK1GOb",
        "outputId": "cdf080dc-e67f-4c19-c193-532864755e95"
      },
      "source": [
        "X_tr = []\n",
        "for i in range(len(X_train)):\n",
        "    x = []\n",
        "    for j in range(12):\n",
        "        p = X_train[i][:1000,j]\n",
        "        if p.shape[0]!= 1000:\n",
        "            d = abs(p.shape[0]-1000)//2\n",
        "            p = np.pad(p,(d,d))\n",
        "        x.append(p)\n",
        "    X_tr.append(np.transpose(x))\n",
        "X_tr = np.array(X_tr)\n",
        "X_tr.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6187, 1000, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qpz5wPKJOxS",
        "outputId": "5beccbd5-5437-4ae2-fc52-eca90cb09e42"
      },
      "source": [
        "X_te = []\n",
        "for i in range(len(X_val)):\n",
        "    x = []\n",
        "    for j in range(12):\n",
        "        p = X_val[i][:1000,j]\n",
        "        if p.shape[0]!= 1000:\n",
        "            d = abs(p.shape[0]-1000)//2\n",
        "            p = np.pad(p,(d,d))\n",
        "        x.append(p)\n",
        "    X_te.append(np.transpose(x))\n",
        "X_te = np.array(X_te)\n",
        "X_te.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(690, 1000, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfvtfMA2K2sw"
      },
      "source": [
        "# from models.fastai_model import fastai_model\n",
        "\n",
        "experiment = 'exp0'\n",
        "modelname = 'fastai_xresnet1d101'\n",
        "pretrainedfolder = '../output0/'+experiment+'/models/'+modelname+'/'\n",
        "mpath='/gdrive/My Drive/ICBEB/' # <=== path where the finetuned model will be stored\n",
        "n_classes_pretrained = 71 # <=== because we load the model from exp0, this should be fixed because this depends the experiment\n",
        "num_classes = 9\n",
        "sampling_frequency = 100\n",
        "input_shape = [1000,12]\n",
        "\n",
        "model = fastai_model(\n",
        "    modelname, \n",
        "    num_classes, \n",
        "    sampling_frequency, \n",
        "    mpath, \n",
        "    input_shape=input_shape, \n",
        "    pretrainedfolder=pretrainedfolder,\n",
        "    n_classes_pretrained=n_classes_pretrained, \n",
        "    pretrained=True,\n",
        "    epochs_finetuning=2,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nz2Up_g3xNNO",
        "outputId": "e93e8cb0-1d14-4116-9507-5cba302aca16"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/gdrive/My Drive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dadm3EOPdeK5"
      },
      "source": [
        "# import pickle\n",
        "\n",
        "standard_scaler = pickle.load(open('../output0/'+experiment+'/data/standard_scaler.pkl', \"rb\"))\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "# X_train = scaler.fit(X_train[i])\n",
        "# X_test = scaler.fit(X_test)\n",
        "\n",
        "X_tr = utils.apply_standardizer(X_tr, standard_scaler)\n",
        "X_te = utils.apply_standardizer(X_te, standard_scaler)\n",
        "\n",
        "# x_train = []\n",
        "# x_test = []\n",
        "\n",
        "# for i in range(len(X_train)):\n",
        "#     tr = X_train[i]\n",
        "#     tr = (tr-np.mean(tr))/(np.std(tr)+1e-30)\n",
        "#     x_train.append(tr)\n",
        "\n",
        "# for i in range(len(X_test)):\n",
        "#     tr = X_test[i]\n",
        "#     tr = (tr-np.mean(tr))/(np.std(tr)+1e-30)\n",
        "#     x_test.append(tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "yMQiix8TZUDV",
        "outputId": "ebd74cab-f659-411a-de55-d33ac0f607d1"
      },
      "source": [
        "plt.plot(X_val[0][:,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc51079e110>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "O9BMIJw_d0TZ",
        "outputId": "c7730044-704c-4c83-f401-a64f50406ab7"
      },
      "source": [
        "plt.plot(X_te[0,:,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc510783110>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdpY5Zmcdlam",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "f287c5d8-1a62-4ffd-d2ca-0a8cb0dce667"
      },
      "source": [
        "model.fit(X_tr, y_train, X_te, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finetuning...\n",
            "model: fastai_xresnet1d101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      33.33% [1/3 00:04<00:08]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.771420</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='46' class='' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      95.83% [46/48 00:04<00:00 1.2945]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.357962</td>\n",
              "      <td>0.296581</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.221781</td>\n",
              "      <td>0.263980</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      33.33% [1/3 00:05<00:10]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.165676</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='42' class='' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      87.50% [42/48 00:04<00:00 0.4873]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.162177</td>\n",
              "      <td>0.265332</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.160792</td>\n",
              "      <td>0.264052</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}